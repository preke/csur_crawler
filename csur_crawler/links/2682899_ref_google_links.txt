http://scholar.google.com/scholar?hl=en&q=S.+Afzal+and+P.+Robinson.+2011.+Natural+affect+data%3A+Collection+and+annotation.+In+New+Perspectives+on+Affect+and+Learning+Technologies%2C+R.+Calvo+and+S.+D%27Mello+%28Eds.%29+Springer%2C+New+York%2C+NY%2C+44%2D%2D70.
http://scholar.google.com/scholar?hl=en&q=J.+Bailenson%2C+E.+Pontikakis%2C+I.+Mauss%2C+J.+Gross%2C+M.+Jabon%2C+C.+Hutcherson%2C+C.+Nass%2C+and+O.+John.+2008.+Real-time+classification+of+evoked+emotions+using+facial+feature+tracking+and+physiological+responses.+Int.+J.+Hum.+Comput.+Stud.+66%2C+303%2D%2D317.+10.1016%2Fj.ijhcs.2007.10.011+
http://scholar.google.com/scholar?hl=en&q=T.+Baltru%C5%A1aitis%2C+N.+Banda%2C+and+P.+Robinson.+2013.+Dimensional+affect+recognition+using+continuous+conditional+random+fields.+In+Proceedings+of+the+International+Conference+on+Multimedia+and+Expo+%28Workshop+on+Affective+Analysis+in+Multimedia%29.
http://scholar.google.com/scholar?hl=en&q=N.+Banda+and+P.+Robinson.+2011.+Noise+analysis+in+audio-visual+emotion+recognition.+In+Proceedings+of+the+11th+International+Conference+on+Multimodal+Interaction+%28ICMI%29.
http://scholar.google.com/scholar?hl=en&q=L.+Barrett.+2006.+Are+emotions+natural+kinds%26quest%3B+Perspect.+Psychol.+Sci.+1%2C+28%2D%2D58.
http://scholar.google.com/scholar?hl=en&q=L.+Barrett%2C+B.+Mesquita%2C+K.+Ochsner%2C+and+J.+Gross.+2007.+The+experience+of+emotion.+Ann.+Rev.+Psychol.+58%2C+373%2D%2D403.
http://scholar.google.com/scholar?hl=en&q=M.+Borenstein%2C+L.+V.+Hedges%2C+J.+P.+T.+Higgins%2C+and+H.+R.+Rothstein.+2009.+Introduction+to+Meta-Analysis.+John+Wiley+%26amp%3B+Sons%2C+Inc.%2C+Hoboken%2C+NJ.
http://scholar.google.com/scholar?hl=en&q=S.+Brave+and+C.+Nass.+2002.+Emotion+in+human-computer+interaction.+In+The+Human-Computer+Interaction+Handbook%3A+Fundamentals%2C+Evolving+Technologies+and+Emerging+Applications%2C+J.+Jacko+and+A.+Sears+%28Eds.%29.+Erlbaum+Associates%2C+Inc.%2C+Hillsdale%2C+NJ%2C+81%2D%2D96.+
http://scholar.google.com/scholar?hl=en&q=C.+Busso%2C+Z.+Deng%2C+S.+Yildirim%2C+M.+Bulut%2C+C.+M.+Lee%2C+A.+Kazemzadeh%2C+S.+Lee%2C+U.+Neumann%2C+and+S.+Narayanan.+2004.+Analysis+of+emotion+recognition+using+facial+expressions%2C+speech+and+multimodal+information.+In+Proceedings+of+the+6th+International+Conference+on+Mutlmodal+Interfaces+%28ICMI%2704%29%2C+R.+Sharma%2C+T.+M.+P.+Darrell+Harper%2C+G.+Lazzari+and+M.+Turk+%28Eds.%29.+ACM%2C+State+College%2C+PA%2C+205%2D%2D211.+10.1145%2F1027933.1027968+
http://scholar.google.com/scholar?hl=en&q=R.+Calvo%2C+S.+K.+D%27Mello%2C+J.+Gratch%2C+and+A.+Kappas.+2014.+The+Oxford+Handbook+of+Affective+Computing.+Oxford+University+Press%2C+New+York%2C+NY.
http://scholar.google.com/scholar?hl=en&q=R.+A.+Calvo+and+S.+K.+D%27Mello.+2010.+Affect+detection%3A+An+interdisciplinary+review+of+models%2C+methods%2C+and+their+applications.+IEEE+Trans.+Affect.+Comput.+1+%282007%29%2C+18%2D%2D37.+10.1109%2FT-AFFC.2010.1+
http://scholar.google.com/scholar?hl=en&q=G.+Caridakis%2C+L.+Malatesta%2C+L.+Kessous%2C+N.+Amir%2C+A.+Paouzaiou%2C+and+K.+Karpouzis.+2006.+Modeling+naturalistic+affective+states+via+facial+and+vocal+expression+recognition.+In+International+Conference+on+Multimidal+Interfaces.+ACM%2C+New+York%2C+NY%2C+146%2D%2D154.+10.1145%2F1180995.1181029+
http://scholar.google.com/scholar?hl=en&q=G.+Castellano%2C+L.+Kessous%2C+and+G.+Caridakis.+2008.+Emotion+recognition+through+multiple+modalities%3A+Face%2C+body+gesture%2C+speech.+In+Affect+and+Emotion+in+Human-Computer+Interaction%2C+C.+Peter+and+R.+Beale+%28Eds.%29.+Lecture+Notes+in+Computer+Science%2C+Vol.+4868.+Springer%2C+Berlin%2C+92%2D%2D103.+10.1007%2F978-3-540-85099-1_8+
http://scholar.google.com/scholar?hl=en&q=G.+Castellano%2C+A.+Pereira%2C+I.+Leite%2C+A.+Paiva%2C+and+P.+McOwan.+2009.+Detecting+user+engagement+with+a+robot+companion+using+task+and+social+interaction-based+features.+In+Proceedings+of+the+2009+International+Conference+on+Multimodal+interfaces.+ACM%2C+New+York%2C+NY%2C+119%2D%2D126.+10.1145%2F1647314.1647336+
http://scholar.google.com/scholar?hl=en&q=G.+Chanel%2C+C.+Rebetez%2C+M.+B%C3%A9trancourt%2C+and+T.+Pun.+2011.+Emotion+assessment+from+physiological+signals+for+adaptation+of+game+difficulty.+IEEE+Trans.+Syst.%2C+Man+Cybern.+Part+A+Syst.+Humans+41%2C+1052%2D%2D1063.+10.1109%2FTSMCA.2011.2116000+
http://scholar.google.com/scholar?hl=en&q=C.-Y.+Chen%2C+Y.-K.+Huang%2C+and+P.+Cook.+2005.+Visual%2FAcoustic+emotion+recognition.+In+Proceedings+of+the+IEEE+International+Conference+on+Multimedia+and+Expo.+IEEE%2C+Washington%2C+DC%2C+1468%2D%2D1471.
http://scholar.google.com/scholar?hl=en&q=G.+Chetty+and+M.+Wagner.+2008.+A+multilevel+fusion+approach+for+audiovisual+emotion+recognition.+In+Proceedings+of+the+International+Conference+on+Auditory-Visual+Speech+Processing%2C+115%2D%2D120.
http://scholar.google.com/scholar?hl=en&q=Z.-J.+Chuang+and+C.-H.+Wu.+2004.+Multi-modal+emotion+recognition+from+speech+and+text.+Int.+J.+Comput.+Ling.+Chin.+Lang.+Process.+9%2C+1%2D%2D18.
http://scholar.google.com/scholar?hl=en&q=J.+A.+Coan.+2010.+Emergent+ghosts+of+the+emotion+machine.+Emotion+Rev.+2%2C+274%2D%2D285.
http://scholar.google.com/scholar?hl=en&q=J.+Cohen.+1992.+A+power+primer.+Psychol.+Bull.+112%2C+155%2D%2D159.
http://scholar.google.com/scholar?hl=en&q=C.+Conati+and+H.+Maclaren.+2009.+Empirically+building+and+evaluating+a+probabilistic+model+of+user+affect.+User+Model.+User-Adapt.+Interact.+19%2C+267%2D%2D303.+10.1007%2Fs11257-009-9062-8+
http://scholar.google.com/scholar?hl=en&q=C.+Conati%2C+S.+Marsella%2C+and+A.+Paiva.+2005.+Affective+interactions%3A+The+computer+in+the+affective+loop.+In+Proceedings+of+the+10th+International+Conference+on+Intelligent+User+Interfaces%2C+J.+Riedl+and+A.+Jameson+%28Eds.%29.+ACM%2C+New+York%2C+NY%2C+7.+10.1145%2F1040830.1040838+
http://scholar.google.com/scholar?hl=en&q=R.+Cowie%2C+E.+Douglas-Cowie%2C+and+C.+Cox.+2005.+Beyond+emotion+archetypes%3A+Databases+for+emotion+modelling+using+neural+networks.+Neur.+Netw.+18%2C+371%2D%2D388.+10.1016%2Fj.neunet.2005.03.002+
http://scholar.google.com/scholar?hl=en&q=R.+Cowie%2C+E.+Douglas-Cowie%2C+N.+Tsapatsoulis%2C+G.+Votsis%2C+S.+Kollias%2C+W.+Fellenz%2C+and+J.+Taylor.+2001.+Emotion+recognition+in+human-computer+interaction.+IEEE+Sig.+Process.+Mag.+18%2C+32%2D%2D80.
http://scholar.google.com/scholar?hl=en&q=D.+Cueva%2C+R.+Gon%C3%A7alves%2C+F.+Cozman%2C+and+M.+Pereira-Barretto.+2011.+Crawling+to+improve+multimodal+emotion+detection.+In+Proceedings+of+the+10th+Mexican+International+Conference+on+Artificial+Intelligence+%28MICAI%2711%29.+Springer-Verlag%2C+Puebla%2C+Mexico%2C+343%2D%2D350.+10.1007%2F978-3-642-25330-0_30+
http://scholar.google.com/scholar?hl=en&q=S.+D%27Mello.+2013.+A+selective+meta-analysis+on+the+relative+incidence+of+discrete+affective+states+during+learning+with+technology.+J.+Educ.+Psychology+Psychol.+105%2C+1082%2D%2D1099.
http://scholar.google.com/scholar?hl=en&q=S.+D%27Mello+and+A.+Graesser.+2007.+Mind+and+body%3A+Dialogue+and+posture+for+affect+detection+in+learning+environments.+In+Proceedings+of+the+13th+International+Conference+on+Artificial+Intelligence+in+Education%2C+R.+Lukin+et+al.+%28Eds.%29.+IOS+Press%2C+Amsterdam%2C+161%2D%2D168.+
http://scholar.google.com/scholar?hl=en&q=S.+D%27Mello+and+A.+Graesser.+2010.+Multimodal+semi-automated+affect+detection+from+conversational+cues%2C+gross+body+language%2C+and+facial+features.+User+Model.+User-Adap.+Interact.+20%2C+147%2D%2D187.+10.1007%2Fs11257-010-9074-4+
http://scholar.google.com/scholar?hl=en&q=S.+D%27Mello+and+A.+Graesser.+2012.+AutoTutor+and+affective+autotutor%3A+Learning+by+talking+with+cognitively+and+emotionally+intelligent+computers+that+talk+back.+ACM+Trans.+Interact.+Intell.+Syst.+2%2C+23%3A22%2D%2D23%3A39.+10.1145%2F2395123.2395128+
http://scholar.google.com/scholar?hl=en&q=S.+D%27Mello+and+J.+Kory.+2012.+Consistent+but+modest%3A+Comparing+multimodal+and+unimodal+affect+detection+accuracies+from+30+studies.+In+Proceedings+of+the+14th+ACM+International+Conference+on+Multimodal+Interaction%2C+L.-P.+Morency%2C+D.+Bohus%2C+H.+Aghajan%2C+A.+Nijholt%2C+J.+Cassell+and+J.+Epps+%28Eds.%29.+ACM+New+York%2C+NY%2C+31%2D%2D38.+10.1145%2F2388676.2388686+
http://scholar.google.com/scholar?hl=en&q=S.+K.+D%27Mello+and+A.+C.+Graesser.+2014.+Confusion.+In+International+Handbook+of+Emotions+in+Education%2C+R.+Pekrun+and+L.+Linnenbrink-Garcia+%28Eds.%29.+Routledge%2C+New+York%2C+NY%2C+289%2D%2D310.
http://scholar.google.com/scholar?hl=en&q=S.+D%27Mello+and+A.+Graesser.+2011.+The+half-life+of+cognitive-affective+states+during+complex+learning.+Cognition+Emotion+25%2C+1299%2D%2D1308.
http://scholar.google.com/scholar?hl=en&q=D.+Datcu+and+L.+Rothkrantz.+2011.+Emotion+recognition+using+bimodal+data+fusion.+In+Proceedings+of+the+12th+International+Conference+on+Computer+Systems+and+Technologies.+ACM%2C+New+York%2C+NY%2C+122%2D%2D128.+10.1145%2F2023607.2023629+
http://scholar.google.com/scholar?hl=en&q=S.+Dobri%C5%A1ek%2C+R.+Gaj%C5%A1ek%2C+F.+Miheli%C4%8D%2C+N.+Pave%C5%A1i%C4%87%2C+and+V.+%C5%A0truc.+2013.+Towards+efficient+multi-modal+emotion+recognition.+Int.+J.+Adv.+Robotic+Syst.+10%2C+1%2D%2D10.
http://scholar.google.com/scholar?hl=en&q=E.+Douglas-Cowie%2C+R.+Cowie%2C+I.+Sneddon%2C+C.+Cox%2C+O.+Lowry%2C+M.+Mcrorie%2C+J.+C.+Martin%2C+L.+Devillers%2C+S.+Abrilian%2C+and+A.+Batliner.+2007.+The+HUMAINE+database%3A+Addressing+the+collection+and+annotation+of+naturalistic+and+induced+emotional+data.+In+Proceedings+of+the+2nd+International+Conference+on+Affective+Computing+and+Intelligent+Interaction.+Springer%2C+Berlin%2C+488%2D%2D500.+10.1007%2F978-3-540-74889-2_43+
http://scholar.google.com/scholar?hl=en&q=S.+Duval+and+R.+Tweedie.+2000.+Trim+and+fill%3A+A+simple+funnel-plot%2D%2Dbased+method+of+testing+and+adjusting+for+publication+bias+in+meta-analysis.+Biometrics+56%2C+455%2D%2D463.
http://scholar.google.com/scholar?hl=en&q=M.+Dy%2C+I.+Espinosa%2C+P.+Go%2C+C.+Mendez%2C+and+J.+Cu.+2010.+Multimodal+emotion+recognition+using+a+spontaneous+Filipino+emotion+database.+In+Proceedings+of+the+3rd+International+Conference+on+Human-Centric+Computing.+IEEE%2C+Washington%2C+DC%2C+1%2D%2D5.
http://scholar.google.com/scholar?hl=en&q=P.+Ekman.+1992.+An+argument+for+basic+emotions.+Cognition+Emotion+6%2C+169%2D%2D200.
http://scholar.google.com/scholar?hl=en&q=H.+Elfenbein+and+N.+Ambady.+2002.+On+the+universality+and+cultural+specificity+of+emotion+recognition%3A+A+meta-analysis.+Psychol.+Bull.+128%2C+203%2D%2D235.
http://scholar.google.com/scholar?hl=en&q=S.+Emerich%2C+E.+Lupu%2C+and+A.+Apatean.+2009.+Emotions+recognition+by+speech+and+facial+expressions+analysis.+In+Proceedings+of+the+17th+European+Signal+Processing+Conference+%28EUSIPCO+2009%29.+Glasgow%2C+Scotland.
http://scholar.google.com/scholar?hl=en&q=F.+Eyben%2C+M.+W%C3%B6llmer%2C+A.+Graves%2C+B.+Schuller%2C+E.+Douglas-Cowie%2C+and+R.+Cowie.+2010.+On-line+emotion+recognition+in+a+3-D+activation-valence-time+continuum+using+acoustic+and+linguistic+cues.+J.+Multimodal+User+Int.+3%2C+7%2D%2D19.
http://scholar.google.com/scholar?hl=en&q=F.+Eyben%2C+M.+Wollmer%2C+M.+F.+Valstar%2C+H.+Gunes%2C+B.+Schuller%2C+and+M.+Pantic.+2011.+String-based+audiovisual+fusion+of+behavioural+events+for+the+assessment+of+dimensional+affect.+In+Ninth+IEEE+International+Conference+on+Automatic+Face+and+Gesture+Recognition+%28FG+2011%29.+IEEE%2C+Santa+Barbara%2C+CA%2C+322%2D%2D329.
http://scholar.google.com/scholar?hl=en&q=J.+Fontaine%2C+K.+Scherer%2C+E.+Roesch%2C+and+P.+Ellsworth.+2007.+The+world+of+emotions+is+not+two-dimensional.+Psychol.+Sci.+18%2C+12+%28Dec.+2007%29+1050%2D%2D1057.
http://scholar.google.com/scholar?hl=en&q=K.+Forbes-Riley+and+D.+Litman.+2004.+Predicting+emotion+in+spoken+dialogue+from+multiple+knowledge+sources.+In+Proceedings+of+the+4th+Meeting+of+the+North+American+Chapter+of+the+Association+for+Computational+Linguistics%3A+Human+Language+Technologies%2C+201%2D%2D208.
http://scholar.google.com/scholar?hl=en&q=K.+Forbes-Riley+and+D.+J.+Litman.+2011.+Benefits+and+challenges+of+real-time+uncertainty+detection+and+adaptation+in+a+spoken+dialogue+computer+tutor.+Speech+Commun.+53%2C+1115%2D%2D1136.+10.1016%2Fj.specom.2011.02.006+
http://scholar.google.com/scholar?hl=en&q=R.+Gajsek%2C+V.+Struc%2C+and+F.+Mihelic.+2010.+Multi-modal+emotion+recognition+using+canonical+correlations+and+acoustic+features.+In+Proceedings+of+the+20th+International+Conference+on+Pattern+Recognition.+IEEE%2C+Washington%2C+DC%2C+4133%2D%2D4136.+10.1109%2FICPR.2010.1005+
http://scholar.google.com/scholar?hl=en&q=M.+Glodek%2C+S.+Reuter%2C+M.+Schels%2C+K.+Dietmayer%2C+and+F.+Schwenker.+2013.+Kalman+filter+based+classifier+fusion+for+affective+state+recognition.+In+Proceedings+of+the+11th+International+Workshop+on+Multiple+Classifier+Systems%2C+Z.-H.+Zhou%2C+F.+Roli%2C+and+J.+Kittler+%28Eds.%29.+Springer%2C+Berlin%2C+85%2D%2D94.
http://scholar.google.com/scholar?hl=en&q=M.+Glodek%2C+S.+Tschechne%2C+G.+Layher%2C+M.+Schels%2C+T.+Brosch%2C+S.+Scherer%2C+M.+K%C3%A4chele%2C+M.+Schmidt%2C+H.+Neumann%2C+and+G.+Palm.+2011.+Multiple+classifier+systems+for+the+classification+of+audio-visual+emotional+states.+In+4th+International+Conference+on+Affective+Computing+and+Intelligent+Interaction+%28ACII%2711%29%2C+S.+D%27Mello%2C+A.+Graesser%2C+B.+Schuller%2C+and+J.+Martin+%28Eds.%29.+Springer%2C+Memphis%2C+TN%2C+359%2D%2D368.+
http://scholar.google.com/scholar?hl=en&q=S.+Gong%2C+C.+Shan%2C+and+T.+Xiang.+2007.+Visual+inference+of+human+emotion+and+behaviour.+In+Proceedings+of+the+9th+International+Conference+on+Multimodal+Interfaces.+ACM%2C+New+York%2C+NY%2C+22%2D%2D29.+10.1145%2F1322192.1322199+
http://scholar.google.com/scholar?hl=en&q=A.+Graesser%2C+B.+McDaniel%2C+P.+Chipman%2C+A.+Witherspoon%2C+S.+D%27Mello%2C+and+B.+Gholson.+2006.+Detection+of+emotions+during+learning+with+AutoTutor.+In+Proceedings+of+the+28th+Annual+Conference+of+the+Cognitive+Science+Society%2C+R.+Sun+and+N.+Miyake+%28Eds.%29.+Cognitive+Science+Society%2C+Austin%2C+TX%2C+285%2D%2D290.
http://scholar.google.com/scholar?hl=en&q=H.+Gunes+and+M.+Piccardi.+2005.+Fusing+face+and+body+display+for+bi-modal+emotion+recognition%3A+Single+frame+analysis+and+multi-frame+post+integration.+In+Proceedings+of+the+1st+International+Conference+on+Affective+Computing+and+Intelligent+Interaction+%28ACII%2705%29%2C+J.+Tao+and+R.+Picard+%28Eds.%29.+Springer-Verlag%2C+102%2D%2D111.+10.1007%2F11573548_14+
http://scholar.google.com/scholar?hl=en&q=H.+Gunes+and+M.+Piccardi.+2009.+Automatic+temporal+segment+detection+and+affect+recognition+from+face+and+body+display.+IEEE+Trans.+Syst.%2C+Man%2C+Cybern.+Part+B+Cybern.+39%2C+64%2D%2D84.+10.1109%2FTSMCB.2008.927269+
http://scholar.google.com/scholar?hl=en&q=M.+Han%2C+J.+Hsu%2C+K.-T.+Song%2C+and+F.-Y.+Chang.+2007.+A+new+information+fusion+method+for+SVM-based+robotic+audio-visual+emotion+recognition.+In+Proceedings+of+the+IEEE+International+Conference+on+Systems%2C+Man+and+Cybernetics.+IEEE%2C+Washington%2C+DC%2C+2656%2D%2D2661.
http://scholar.google.com/scholar?hl=en&q=S.+Haq+and+P.+Jackson.+2009.+Speaker-dependent+audio-visual+emotion+recognition.+In+Proceedings+of+International+Conference+on+Auditory-Visual+Speech+Processing%2C+53%2D%2D58.
http://scholar.google.com/scholar?hl=en&q=S.+Haq%2C+P.+Jackson%2C+and+J.+Edge.+2008.+Audio-visual+feature+selection+and+reduction+for+emotion+classification.+In+Proceedings+of+the+International+Conference+on+Auditory-Visual+Speech+Processing%2C+185%2D%2D190.
http://scholar.google.com/scholar?hl=en&q=S.+Hoch%2C+F.+Althoff%2C+G.+McGlaun%2C+and+G.+Rigoll.+2005.+Bimodal+fusion+of+emotional+data+in+an+automotive+environment.+In+Proceedings+of+the+IEEE+International+Conference+on+Acoustics%2C+Speech%2C+and+Signal+Processing.+IEEE%2C+Washington%2C+DC%2C+1085%2D%2D1088.
http://scholar.google.com/scholar?hl=en&q=S.+Hommel%2C+A.+Rabie%2C+and+U.+Handmann.+2013.+Attention+and+emotion+based+adaption+of+dialog+systems.+In+Intelligent+Systems%3A+Models+and+Applications%2C+E.+Pap+%28Ed.%29.+Springer-Verlag%2C+Berlin%2C+215%2D%2D235.
http://scholar.google.com/scholar?hl=en&q=M.+Hoque+and+R.+W.+Picard.+2011.+Acted+vs.+natural+frustration+and+delight%3A+Many+people+smile+in+natural+frustration.+In+Proceedings+of+the+IEEE+International+Conference+on+Automatic+Face+and+Gesture+Recognition+and+Workshops+%28FG%2711%29.+IEEE%2C+Washington%2C+DC%2C+354%2D%2D359.
http://scholar.google.com/scholar?hl=en&q=M.+Hussain%2C+H.+Monkaresi%2C+and+R.+Calvo.+2012.+Combining+classifiers+in+multimodal+affect+detection.+In+Proceedings+of+the+Australasian+Data+Mining+Conference.+
http://scholar.google.com/scholar?hl=en&q=C.+Izard.+2010.+The+many+meanings%2Faspects+of+emotion%3A+Definitions%2C+functions%2C+activation%2C+and+regulation.+Emotion+Rev.+2%2C+363%2D%2D370.
http://scholar.google.com/scholar?hl=en&q=C.+E.+Izard.+2007.+Basic+emotions%2C+natural+kinds%2C+emotion+schemas%2C+and+a+new+paradigm.+Perspect.+Psychol.+Sci.+2%2C+260%2D%2D280.
http://scholar.google.com/scholar?hl=en&q=A.+Jaimes+and+N.+Sebe.+2007.+Multimodal+human-computer+interaction%3A+A+survey.+Comput.+Vision+Image+Understanding+108%2C+116%2D%2D134.+10.1016%2Fj.cviu.2006.10.019+
http://scholar.google.com/scholar?hl=en&q=L.+Jeni%2C+J.+Cohn%2C+and+F.+De+La+Torre.+2013.+Facing+imbalanced+data%E2%80%94Recommendations+for+the+use+of+performance+metrics.+In+Proceedings+of+the+2013+Humaine+Association+Conference+on+Affective+Computing+and+Intelligent+Interaction+%28ACII%2713%29%2C+A.+Nijholt%2C+S.+K.+D%27Mello%2C+and+M.+Pantic+%28Eds.%29.+IEEE%2C+Washington%2C+DC%2C+245%2D%2D251.+10.1109%2FACII.2013.47+
http://scholar.google.com/scholar?hl=en&q=D.+Jiang%2C+Y.+Cui%2C+X.+Zhang%2C+P.+Fan%2C+I.+Ganzalez%2C+and+H.+Sahli.+2011.+Audio+visual+emotion+recognition+based+on+triple-stream+dynamic+bayesian+network+models.+In+Proceedings+of+the+4th+International+Conference+on+Affective+Computing+and+Intelligent+Interaction%2C+S.+D%27Mello%2C+A.+Graesser%2C+B.+Schuller%2C+and+J.+Martin+%28Eds.%29.+Springer-Verlag%2C+609%2D%2D618.+
http://scholar.google.com/scholar?hl=en&q=J.-T.+Joo%2C+S.-W.+Seo%2C+K.-E.+Ko%2C+and+K.-B.+Sim.+2007.+Emotion+recognition+method+based+on+multimodal+sensor+fusion+algorithm.+In+Proceedings+of+the+8th+Symposium+on+Advanced+Intelligent+Systems.+200%2D%2D204.
http://scholar.google.com/scholar?hl=en&q=C.+Kaernbach.+2011.+On+dimensions+in+emotion+psychology.+In+Proceedings+of+the+IEEE+International+Conference+on+Automatic+Face+and+Gesture+Recognition+and+Workshops.+IEEE%2C+Washington%2C+DC%2C+792%2D%2D796.
http://scholar.google.com/scholar?hl=en&q=I.+Kanluan%2C+M.+Grimm%2C+and+K.+Kroschel.+2008.+Audio-visual+emotion+recognition+using+an+emotion+space+concept.+In+Proceedings+of+the+16th+European+Signal+Processing+Conference.
http://scholar.google.com/scholar?hl=en&q=A.+Kapoor%2C+B.+Burleson%2C+and+R.+Picard.+2007.+Automatic+prediction+of+frustration.+Int.+J.+Hum.Comput.+Stud.+65%2C+724%2D%2D736.+10.1016%2Fj.ijhcs.2007.02.003+
http://scholar.google.com/scholar?hl=en&q=A.+Kapoor+and+R.+Picard.+2005.+Multimodal+affect+recognition+in+learning+environments.+In+Proceedings+of+the+13th+Annual+ACM+International+Conference+on+Multimedia.+ACM%2C+New+York%2C+NY%2C+677%2D%2D682.+10.1145%2F1101149.1101300+
http://scholar.google.com/scholar?hl=en&q=K.+Karpouzis%2C+G.+Caridakis%2C+L.+Kessous%2C+N.+Amir%2C+A.+Raouzaiou%2C+L.+Malatesta%2C+and+S.+Kollias.+2007.+Modeling+naturalistic+affective+states+via+facial%2C+vocal%2C+and+bodily+expressions+recognition.+In+Artifical+Intelligence+for+Human+Computing%2C+T.+Huang+%28Ed.%29.+Springer-Verlag%2C+Berlin%2C+91%2D%2D112.+
http://scholar.google.com/scholar?hl=en&q=L.+Kessous%2C+G.+Castellano%2C+and+G.+Caridakis.+2010.+Multimodal+emotion+recognition+in+speech-based+interaction+using+facial+expression%2C+body+gesture+and+acoustic+analysis.+J.+Multimodal+User+Int.+3%2C+33%2D%2D48.
http://scholar.google.com/scholar?hl=en&q=Z.+Khalali+and+M.+Moradi.+2009.+Emotion+recognition+system+using+brain+and+peripheral+signals%3A+Using+correlation+dimension+to+improve+the+results+of+EEG.+In+Proceedings+of+International+Joint+Conference+on+Neural+Networks.+IEEE%2C+Los+Alamitos%2C+CA%2C+1571%2D%2D1575.+
http://scholar.google.com/scholar?hl=en&q=J.+Kim.+2007.+Bimodal+emotion+recognition+using+speech+and+physiological+changes.+In+Robust+Speech+Recognition+and+Understanding%2C+M.+Grimm+and+K.+Kroschel+%28Eds.%29.+I-Tech%2C+265%2D%2D280.
http://scholar.google.com/scholar?hl=en&q=J.+Kim%2C+E.+Andr%C3%A9%2C+M.+Rehm%2C+T.+Vogt%2C+and+J.+Wagner.+2005.+Integrating+information+from+speech+and+physiological+signals+to+achieve+emotional+sensitivity.+In+Proceedings+of+9th+European+Conference+on+Speech+Communication+and+Technology.+809%2D%2D812.
http://scholar.google.com/scholar?hl=en&q=J.+Kim+and+F.+Lingenfelser.+2010.+Ensemble+approaches+to+parametric+decision+fusion+for+bimodal+emotion+recognition.+In+Proceedings+of+the+International+Conference+on+Bio-Inspired+Systems+and+Signal+Processing.+BIOSTEC%2C+460%2D%2D463.
http://scholar.google.com/scholar?hl=en&q=S.+Koelstra%2C+C.+Muhl%2C+M.+Soleymani%2C+J.-S.+Lee%2C+A.+Yazdani%2C+T.+Ebrahimi%2C+T.+Pun%2C+A.+Nijholt%2C+and+I.+Patras.+2012.+Deap%3A+A+database+for+emotion+analysis+using+physiological+signals.+IEEE+Trans.+Affect.+Comput.+3%2C+18%2D%2D31.+10.1109%2FT-AFFC.2011.15+
http://scholar.google.com/scholar?hl=en&q=J.+Kory+and+S.+K.+D%27Mello.+2014.+Affect+elicitation+for+affective+computing.+In+The+Oxford+Handbook+of+Affective+Computing%2C+R.+Calvo%2C+S.+D%27Mello%2C+J.+Gratch%2C+and+A.+Kappas+%28Eds.%29.+Oxford+University+Press%2C+New+York%2C+NY.
http://scholar.google.com/scholar?hl=en&q=G.+Krell%2C+M.+Glodek%2C+A.+Panning%2C+I.+Siegert%2C+B.+Michaelis%2C+A.+Wendemuth%2C+and+F.+Schwenker.+2013.+Fusion+of+fragmentary+classifier+decisions+for+affective+state+recognition.+In+Proceedings+of+the+1st+International+Workshop+on+Multimodal+Pattern+Recognition+of+Social+Signals+in+Human-Computer-Interaction%2C+F.+Schwenker%2C+S.+Scherer%2C+and+L.-P.+Morency+%28Eds.%29.+Springer-Verlag%2C+Berlin%2C+116%2D%2D130.+10.1007%2F978-3-642-37081-6_13+
http://scholar.google.com/scholar?hl=en&q=M.+D.+Lewis.+2005.+Bridging+emotion+theory+and+neurobiology+through+dynamic+systems+modeling.+Behav.+Brain+Sci.+28%2C+169%2D%2D245.
http://scholar.google.com/scholar?hl=en&q=J.+Lin%2C+C.+Wu%2C+and+W.+Wei.+2012.+Error+weighted+semi-coupled+hidden+markov+model+for+audio-visual+emotion+recognition.+IEEE+Trans.+Multimedia+14%2C+142%2D%2D156.+10.1109%2FTMM.2011.2171334+
http://scholar.google.com/scholar?hl=en&q=F.+Lingenfelser%2C+J.+Wagner%2C+and+E.+Andr%C3%A9.+2011.+A+systematic+discussion+of+fusion+techniques+for+multi-modal+affect+recognition+tasks.+In+Proceedings+of+the+13th+International+Conference+on+Multimodal+Interfaces.+ACM%2C+New+York%2C+NY%2C+19%2D%2D26.+10.1145%2F2070481.2070487+
http://scholar.google.com/scholar?hl=en&q=M.+W.+Lipsey+and+D.+B.+Wilson.+2001.+Practical+meta-analysis.+Sage+Publications%2C+Inc%2C+Thousand+Oaks%2C+CA.
http://scholar.google.com/scholar?hl=en&q=D.+Litman+and+K.+Forbes-Riley.+2004.+Predicting+student+emotions+in+computer-human+tutoring+dialogues.+In+Proceedings+of+the+42nd+Annual+Meeting+on+Association+for+Computational+Linguistics.+Association+for+Computational+Linguistics%2C+Barcelona%2C+Spain%2C+352%2D%2D359.+10.3115%2F1218955.1219000+
http://scholar.google.com/scholar?hl=en&q=D.+Litman+and+K.+Forbes-Riley.+2006a.+Recognizing+student+emotions+and+attitudes+on+the+basis+of+utterances+in+spoken+tutoring+dialogues+with+both+human+and+computer+tutors.+Speech+Commun.+48%2C+559%2D%2D590.
http://scholar.google.com/scholar?hl=en&q=D.+J.+Litman+and+K.+Forbes-Riley.+2006b.+Recognizing+student+emotions+and+attitudes+on+the+basis+of+utterances+in+spoken+tutoring+dialogues+with+both+human+and+computer+tutors.+Speech+Commun.+48%2C+559%2D%2D590.
http://scholar.google.com/scholar?hl=en&q=K.+Lu+and+Y.+Jia.+2012.+Audio-visual+emotion+recognition+with+boosted+coupled+HMM.+In+Proceedings+of+the+21st+International+Conference+on+Pattern+Recognition.+IEEE%2C+Washington%2C+DC%2C+1148%2D%2D1151.
http://scholar.google.com/scholar?hl=en&q=M.+Mansoorizadeh+and+N.+Charkari.+2010.+Multimodal+information+fusion+application+to+human+emotion+recognition+from+face+and+speech.+Multimedia+Tools+Appl.+49%2C+277%2D%2D297.+10.1007%2Fs11042-009-0344-2+
http://scholar.google.com/scholar?hl=en&q=D.+McDuff%2C+R.+Kaliouby%2C+and+R.+W.+Picard.+2012.+Crowdsourcing+facial+responses+to+online+videos.+IEEE+Trans.+Affective+Comput.+3%2C+456%2D%2D468.+10.1109%2FT-AFFC.2012.19+
http://scholar.google.com/scholar?hl=en&q=G.+McKeown%2C+M.+Valstar%2C+R.+Cowie%2C+M.+Pantic%2C+and+M.+Schroder.+2012.+The+SEMAINE+database%3A+Annotated+multimodal+records+of+emotionally+coloured+conversations+between+a+person+and+a+limited+agent.+IEEE+Trans.+Affective+Comput.+3%2C+5%2D%2D17.+10.1109%2FT-AFFC.2011.20+
http://scholar.google.com/scholar?hl=en&q=A.+Metallinou%2C+S.+Lee%2C+and+S.+Narayanan.+2008.+Audio-visual+emotion+recognition+using+Gaussian+mixture+models+for+face+and+voice.+In+Proceedings+of+the+10th+IEEE+International+Symposium+on+Multimedia.+IEEE%2C+Washington%2C+DC%2C+250%2D%2D257.+10.1109%2FISM.2008.40+
http://scholar.google.com/scholar?hl=en&q=A.+Metallinou%2C+M.+Wollmer%2C+A.+Katsamanis%2C+F.+Eyben%2C+B.+Schuller%2C+and+S.+Narayanan.+2012.+Context-sensitive+learning+for+enhanced+audiovisual+emotion+classification.+IEEE+Trans.+Affective+Comput.+3%2C+184%2D%2D198.+10.1109%2FT-AFFC.2011.40+
http://scholar.google.com/scholar?hl=en&q=H.+Monkaresi%2C+M.+S.+Hussain%2C+and+R.+Calvo.+2012.+Classification+of+affects+using+head+movement%2C+skin+color+features+and+physiological+signals.+In+Proceedings+of+the+IEEE+International+Conference+on+Systems%2C+Man%2C+and+Cybernetics.+IEEE%2C+Washington%2C+DC%2C+2664%2D%2D2669.
http://scholar.google.com/scholar?hl=en&q=M.+Nicolaou%2C+H.+Gunes%2C+and+M.+Pantic.+2011.+Continuous+prediction+of+spontaneous+affect+from+multiple+cues+and+modalities+in+valence+and+arousal+space.+IEEE+Trans.+Affective+Comput.+2%2C+92%2D%2D105.+10.1109%2FT-AFFC.2011.9+
http://scholar.google.com/scholar?hl=en&q=J.+Ocumpaugh%2C+R.+Baker%2C+S.+Gowda%2C+N.+Heffernan%2C+and+C.+Heffernan.+2014.+Population+validity+for+educational+data+mining%3A+A+case+study+in+affect+detection.+Brit.+J.+Educ.+Psychol.+45%2C+487%2D%2D501.
http://scholar.google.com/scholar?hl=en&q=A.+Ortony%2C+G.+Clore%2C+and+A.+Collins.+1988.+The+Cognitive+Structure+of+Emotions.+Cambridge+University+Press%2C+New+York.
http://scholar.google.com/scholar?hl=en&q=P.+Pal%2C+A.+Iyer%2C+and+R.+Yantorno.+2006.+Emotion+detection+from+infant+facial+expressions+and+cries.+In+Proceedings.+of+the+2006+IEEE+International+Conference+on+Acoustics%2C+Speech+and+Signal+Processing.+IEEE%2C+Washington%2C+DC%2C+721%2D%2D724.
http://scholar.google.com/scholar?hl=en&q=M.+Paleari%2C+R.+Benmokhtar%2C+and+B.+Huet.+2009.+Evidence+theory-based+multimodal+emotion+recognition.+In+Proceedings+of+the+15th+International+Multimedia+Modeling+Conference+%28MMM%2709%29.+Springer-Verlag%2C+435%2D%2D446.+10.1007%2F978-3-540-92892-8_44+
http://scholar.google.com/scholar?hl=en&q=B.+Pang+and+L.+Lee.+2008.+Opinion+mining+and+sentiment+analysis.+Found.+Trends+Inf.+Retrieval+2%2C+1%2D%2D135.+10.1561%2F1500000011+
http://scholar.google.com/scholar?hl=en&q=M.+Pantic+and+L.+Rothkrantz.+2003.+Toward+an+affect-sensitive+multimodal+human-computer+interaction.+Proc.+IEEE+91%2C+1370%2D%2D1390.
http://scholar.google.com/scholar?hl=en&q=J.+Park%2C+G.+Jang%2C+and+Y.+Seo.+2012.+Music-aided+affective+interaction+between+human+and+service+robot.+EURASIP+J.+Audio%2C+Speech%2C+Music+Process.+2012%2C+1%2C+1%2D%2D13.
http://scholar.google.com/scholar?hl=en&q=R.+Picard.+1997.+Affective+Computing.+MIT+Press%2C+Cambridge%2C+Mass.+
http://scholar.google.com/scholar?hl=en&q=R.+Picard.+2010.+Affective+Computing%3A+From+Laughter+to+IEEE.+IEEE+Trans.+Affective+Comput.+1%2C+11%2D%2D17.+10.1109%2FT-AFFC.2010.10+
http://scholar.google.com/scholar?hl=en&q=R.+Plutchik.+2001.+The+nature+of+emotions.+American+Scientist+89%2C+344%2D%2D350.
http://scholar.google.com/scholar?hl=en&q=A.+Rabie%2C+B.+Wrede%2C+T.+Vogt%2C+and+M.+Hanheide.+2009.+Evaluation+and+discussion+of+multi-modal+emotion+recognition.+In+Proceedings+of+the+Second+International+Conference+on+Computer+and+Electrical+Engineering+%28ICCEE%2709%29.+IEEE+Computer+Society%2C+598%2D%2D602.+10.1109%2FICCEE.2009.192+
http://scholar.google.com/scholar?hl=en&q=M.+Rashid%2C+S.+Abu-Bakar%2C+and+M.+Mokji.+2012.+Human+emotion+recognition+from+videos+using+spatio-temporal+and+audio+features.+Visual+Comput.+29%2C+12%2C+1269%2D%2D1275.+10.1007%2Fs00371-012-0768-y+
http://scholar.google.com/scholar?hl=en&q=G.+Rigoll%2C+R.+Muller%2C+and+B.+Schuller.+2005.+Speech+emotion+recognition+exploiting+acoustic+and+linguistic+information+sources.+In+Proceedings+of+the+10th+International+Conference+Speech+and+Computer.+61%2D%2D67.
http://scholar.google.com/scholar?hl=en&q=V.+Rosas%2C+R.+Mihalcea%2C+and+L.+Morency.+2013.+Multimodal+sentiment+analysis+of+spanish+online+videos.+IEEE+Intell.+Syst.+28%2C+38%2D%2D45.+10.1109%2FMIS.2013.9+
http://scholar.google.com/scholar?hl=en&q=E.+Rosenberg.+1998.+Levels+of+analysis+and+the+organization+of+affect.+Rev.+Gen.+Psychol.+2%2C+247%2D%2D270.
http://scholar.google.com/scholar?hl=en&q=E.+Rosenberg+and+P.+Ekman.+1994.+Coherence+between+expressive+and+experiential+systems+in+emotion.+Cognition+Emotion+8%2C+201%2D%2D229.
http://scholar.google.com/scholar?hl=en&q=V.+Rozgic%2C+S.+Ananthakrishnan%2C+S.+Saleem%2C+R.+Kumar%2C+and+R.+Prasad.+2012.+Ensemble+of+SVM+trees+for+multimodal+emotion+recognition.+In+Proceedings+of+the+Signal+and+Information+Processing+Association+Annual+Summit+and+Conference.+IEEE%2C+Washington%2C+DC%2C+1%2D%2D4.
http://scholar.google.com/scholar?hl=en&q=J.+Russell.+1994.+Is+there+universal+recognition+of+emotion+from+facial+expression%26quest%3B+A+review+of+the+cross-cultural+studies.+Psychol.+Bull.+115%2C+102%2D%2D141.
http://scholar.google.com/scholar?hl=en&q=J.+Russell.+2003.+Core+affect+and+the+psychological+construction+of+emotion.+Psychol.+Rev.+110%2C+145%2D%2D172.
http://scholar.google.com/scholar?hl=en&q=J.+A.+Russell%2C+J.+A.+Bachorowski%2C+and+J.+M.+Fernandez-Dols.+2003.+Facial+and+vocal+expressions+of+emotion.+Ann.+Rev.+Psychol.+54%2C+329%2D%2D349.
http://scholar.google.com/scholar?hl=en&q=A.+Savran%2C+H.+Cao%2C+M.+Shah%2C+A.+Nenkova%2C+and+R.+Verma.+2012.+Combining+video%2C+audio+and+lexical+indicators+of+affect+in+spontaneous+conversation+via+particle+filtering.+In+Proceedings+of+the+14th+ACM+International+Conference+on+Multimodal+Interaction.+ACM+Press%2C+New+York%2C+NY%2C+485%2D%2D492.+10.1145%2F2388676.2388781+
http://scholar.google.com/scholar?hl=en&q=B.+Schuller.+2011.+Recognizing+affect+from+linguistic+information+in+3D+continuous+space.+IEEE+Trans.+Affective+Comput.+2%2C+192%2D%2D205.+10.1109%2FT-AFFC.2011.17+
http://scholar.google.com/scholar?hl=en&q=B.+Schuller%2C+R.+M%C3%BCeller%2C+B.+H%C3%B6ernler%2C+A.+H%C3%B6ethker%2C+H.+Konosu%2C+and+G.+Rigoll.+2007.+Audiovisual+recognition+of+spontaneous+interest+within+conversations.+In+Proceedings+of+the+9th+International+Conference+on+Multimodal+Interfaces.+ACM%2C+New+York%2C+NY%2C+30%2D%2D37.+10.1145%2F1322192.1322201+
http://scholar.google.com/scholar?hl=en&q=N.+Sebe%2C+I.+Cohen%2C+T.+Gevers%2C+and+T.+Huang.+2006.+Emotion+recognition+based+on+joint+visual+and+audio+cues.+In+Proceedings+of+the+18th+International+Conference+on+Pattern+Recognition.+IEEE%2C+Washington%2C+DC%2C+1136%2D%2D1139.+10.1109%2FICPR.2006.489+
http://scholar.google.com/scholar?hl=en&q=D.+Seppi%2C+A.+Batliner%2C+B.+Schuller%2C+S.+Steidl%2C+T.+Vogt%2C+J.+Wagner%2C+L.+Devillers%2C+L.+Vidrascu%2C+N.+Amir%2C+and+V.+Aharonson.+2008.+Patterns%2C+prototypes%2C+performance%3A+Classifying+emotional+user+states.+In+Proceedings+of+the+9th+Annual+Conference+of+the+International+Speech+Communication+Association%2C+601%2D%2D604.
http://scholar.google.com/scholar?hl=en&q=C.+Shan%2C+S.+Gong%2C+and+P.+McOwan.+2007.+Beyond+facial+expressions%3A+Learning+human+emotion+from+body+gestures.+In+Proceedings+of+the+British+Machine+Vision+Conference%2C+1%2D%2D10.
http://scholar.google.com/scholar?hl=en&q=M.+Soleymani%2C+M.+Pantic%2C+and+T.+Pun.+2012.+Multi-modal+emotion+recognition+in+response+to+videos.+IEEE+Trans.+Affective+Comput.+3%2C+211%2D%2D223.+10.1109%2FT-AFFC.2011.37+
http://scholar.google.com/scholar?hl=en&q=A.+Sutdiffe.+2008.+Multimedia+user+interface+design.+In+The+Human-Computer+Interaction+Handbook%3A+Fundamentals%2C+Evolving+Technologies+and+Emerging+Applications%2C+A.+Sears+and+J.+Jacko+%28Eds.%29.+Taylor+%26amp%3B+Francis%2C+New+York%2C+NY%2C+245%2D%2D261.+
http://scholar.google.com/scholar?hl=en&q=S.+S.+Tomkins.+1962.+Affect+Imagery+Consciousness%3A+Volume+I%2C+The+Positive+Affects.+Tavistock%2C+London.
http://scholar.google.com/scholar?hl=en&q=B.+Tu+and+F.+Yu.+2012.+Bimodal+emotion+recognition+based+on+speech+signals+and+facial+expression.+In+Proceedings+of+the+6th+International+Conference+on+Intelligent+Systems+and+Knowledge.+Springer%2C+Berlin%2C+691%2D%2D696.
http://scholar.google.com/scholar?hl=en&q=J.+Tukey+and+D.+McLaughlin.+1963.+Less+vulnerable+confidence+and+significance+procedures+for+location+based+on+a+single+sample%3A+Trimming%2FWinsorization+1.+Sankhy%C4%81%3A+The+Indian+Journal+of+Statistics+25%2C+331%2D%2D352.
http://scholar.google.com/scholar?hl=en&q=M.+Valstar%2C+M.+Mehu%2C+B.+Jiang%2C+M.+Pantic%2C+and+K.+Scherer.+2012.+Meta-analysis+of+the+first+facial+expression+recognition+challenge.+IEEE+Trans.+Syst.%2C+Man%2C+Cybern.+Part+B+Cybern.+42%2C+966%2D%2D979.+10.1109%2FTSMCB.2012.2200675+
http://scholar.google.com/scholar?hl=en&q=M.+van+der+Zwaag%2C+J.+Janssen%2C+and+J.+Westerink.+2013.+Directing+physiology+and+mood+through+music%3A+Validation+of+an+affective+music+player.+IEEE+Trans.+Affective+Comput.+4%2C+57%2D%2D68.+10.1109%2FT-AFFC.2012.28+
http://scholar.google.com/scholar?hl=en&q=H.+Vu%2C+Y.+Yamazaki%2C+F.+Dong%2C+and+K.+Hirota.+2011.+Emotion+recognition+based+on+human+gesture+and+speech+information+using+RT+middleware.+In+IEEE+International+Conference+on+Fuzzy+Systems.+IEEE%2C+Washington%2C+DC%2C+787%2D%2D791.
http://scholar.google.com/scholar?hl=en&q=J.+Wagner%2C+E.+Andre%2C+F.+Lingenfelser%2C+J.+Kim%2C+and+T.+Vogt.+2011.+Exploring+fusion+methods+for+multimodal+emotion+recognition+with+missing+data.+IEEE+Trans.+Affective+Comput.+2%2C+206%2D%2D218.+10.1109%2FT-AFFC.2011.12+
http://scholar.google.com/scholar?hl=en&q=S.+Walter%2C+S.+Scherer%2C+M.+Schels%2C+M.+Glodek%2C+D.+Hrabal%2C+M.+Schmidt%2C+R.+B%C3%B6ck%2C+K.+Limbrecht%2C+H.+Traue%2C+and+F.+Schwenker.+2011.+Multimodal+emotion+classification+in+naturalistic+user+behavior.+In+Proceedings+of+the+International+Conference+on+Human-Computer+Interaction%2C+J.+Jacko+%28Ed.%29.+Springer%2C+Berlin%2C+603%2D%2D611.+
http://scholar.google.com/scholar?hl=en&q=S.+Wang%2C+Y.+Zhu%2C+G.+Wu%2C+and+Q.+Ji.+2013.+Hybrid+video+emotional+tagging+using+users%27+EEG+and+video+content.+Multimed.+Tools+Appl.+1%2D%2D27.+10.1007%2Fs11042-013-1450-8+
http://scholar.google.com/scholar?hl=en&q=Y.+Wang+and+L.+Guan.+2005.+Recognizing+human+emotion+from+audiovisual+information.+In+Proceedings+of+the+IEEE+International+Conference+on+Acoustics%2C+Speech%2C+and+Signal+Processing.+IEEE%2C+Washington%2C+DC%2C+1125%2D%2D1128.
http://scholar.google.com/scholar?hl=en&q=Y.+Wang+and+L.+Guan.+2008.+Recognizing+human+emotional+state+from+audiovisual+signals.+IEEE+Trans.+Multimedia+10%2C+936%2D%2D946.+10.1109%2FTMM.2008.927665+
http://scholar.google.com/scholar?hl=en&q=M.+Wimmer%2C+B.+Schuller%2C+D.+Arsic%2C+G.+Rigoll%2C+and+B.+Radig.+2008.+Low-level+fusion+of+audio+and+video+feature+for+multi-modal+emotion+recognition.+In+Proceedings+of+the+3rd+International+Conference+on+Computer+Vision+Theory+and+Applications%2C+145%2D%2D151.
http://scholar.google.com/scholar?hl=en&q=M.+W%C3%B6llmer%2C+M.+Kaiser%2C+F.+Eyben%2C+and+B.+Schuller.+2013a.+LSTM+modeling+of+continuous+emotions+in+an+audiovisual+affect+recognition+framework.+Image+Vision+Comput.+31%2C+2+%28Feb.+2013%29%2C+153%2D%2D163.+10.1016%2Fj.imavis.2012.03.001+
http://scholar.google.com/scholar?hl=en&q=M.+W%C3%B6llmer%2C+A.+Metallinou%2C+F.+Eyben%2C+B.+Schuller%2C+and+S.+S.+Narayanan.+2010.+Context-sensitive+multimodal+emotion+recognition+from+speech+and+facial+expression+using+bidirectional+LSTM+modeling.+In+Proceedings+of+the+11th+Annual+Conference+of+the+International+Speech+Communication+Association+%28INTERSPEECH%2710%29.+2362%2D%2D2365.
http://scholar.google.com/scholar?hl=en&q=M.+W%C3%B6llmer%2C+F.+Weninger%2C+T.+Knaup%2C+B.+Schuller%2C+C.+Sun%2C+K.+Sagae%2C+and+L.+Morency.+2013b.+YouTube+movie+reviews%3A+Sentiment+analysis+in+an+audiovisual+context.+IEEE+Intell.+Syst.+28%2C+46%2D%2D53.+10.1109%2FMIS.2013.34+
http://scholar.google.com/scholar?hl=en&q=C.+Wu+and+W.+Liang.+2011.+Emotion+recognition+of+affective+speech+based+on+multiple+classifiers+using+acoustic-prosodic+information+and+semantic+labels.+IEEE+Trans.+Affective+Comput.+2%2C+10%2D%2D21.+10.1109%2FT-AFFC.2010.16+
http://scholar.google.com/scholar?hl=en&q=Z.+Zeng%2C+Y.+Hu%2C+Y.+Fu%2C+T.+Huang%2C+G.+Roisman%2C+and+Z.+Wen.+2006.+Audio-visual+emotion+recognition+in+adult+attachment+interview.+In+Proceedings+of+the+8th+International+Conference+on+Multimodal+Interfaces.+ACM%2C+Washington%2C+DC%2C+139%2D%2D145.+10.1145%2F1180995.1181028+
http://scholar.google.com/scholar?hl=en&q=Z.+Zeng%2C+M.+Pantic%2C+G.+Roisman%2C+and+T.+Huang.+2009.+A+survey+of+affect+recognition+methods%3A+Audio%2C+visual%2C+and+spontaneous+expressions.+IEEE+Trans.+Pattern+Anal.+Mach.+Intell.+31%2C+39%2D%2D58.+10.1109%2FTPAMI.2008.52+
http://scholar.google.com/scholar?hl=en&q=Z.+Zeng%2C+J.+Tu%2C+M.+Liu%2C+and+T.+Huang.+2005.+Multi-stream+confidence+analysis+for+audio-visual+affect+recognition.+In+Proceedings+of+the+1st+International+Conference+on+Affective+Computing+and+Intelligent+Interaction%2C+J.+Tao.%2C+T.+Tan.+and+R.+Picard.+%28Eds.%29.+Springer%2C+Berlin%2C+964%2D%2D971.+10.1007%2F11573548_123+
http://scholar.google.com/scholar?hl=en&q=Z.+Zeng%2C+J.+Tu%2C+M.+Liu%2C+T.+Huang%2C+B.+Pianfetti%2C+D.+Roth%2C+and+S.+Levinson.+2007.+Audio-visual+affect+recognition.+IEEE+Trans.+Multimedia+9%2C+424%2D%2D428.+10.1109%2FTMM.2006.886310+
