http://scholar.google.com/scholar?hl=en&q=Julius+Adebayo+and+Lalana+Kagal.+2016.+Iterative+orthogonal+feature+projection+for+diagnosing+bias+in+black-box+models.+arXiv+preprint+arXiv%3A1611.04967.
http://scholar.google.com/scholar?hl=en&q=Philip+Adler%2C+Casey+Falk%2C+Sorelle+A.+Friedler%2C+Gabriel+Rybeck%2C+Carlos+Scheidegger%2C+Brandon+Smith%2C+and+Suresh+Venkatasubramanian.+2016.+Auditing+black-box+models+for+indirect+influence.+In+Proceedings+of+the+IEEE+16th+International+Conference+on+Data+Mining+%28ICDM%E2%80%9916%29.+IEEE%2C+Springer%2C+1%2D%2D10.
http://scholar.google.com/scholar?hl=en&q=Rakesh+Agrawal%2C+Ramakrishnan+Srikant+et+al.+1994.+Fast+algorithms+for+mining+association+rules.+In+Proceedings+of+the+20th+International+Conference+on+Very+Large+Data+Bases+%28VLDB%E2%80%9994%29%2C+Vol.+1215.+487%2D%2D499.+
http://scholar.google.com/scholar?hl=en&q=Yousra+Abdul+Alsahib+S.+Aldeen%2C+Mazleena+Salleh%2C+and+Mohammad+Abdur+Razzaque.+2015.+A+comprehensive+review+on+privacy+preserving+data+mining.+SpringerPlus+4%2C+1+%282015%29%2C+694.
http://scholar.google.com/scholar?hl=en&q=Robert+Andrews%2C+Joachim+Diederich%2C+and+Alan+B.+Tickle.+1995.+Survey+and+critique+of+techniques+for+extracting+rules+from+trained+artificial+neural+networks.+Knowl.-Based+Syst.+8%2C+6+%281995%29%2C+373%2D%2D389.+10.1016%2F0950-7051%2896%2981920-4+
http://scholar.google.com/scholar?hl=en&q=M.+Gethsiyal+Augasta+and+T.+Kathirvalavakumar.+2012.+Reverse+engineering+the+neural+networks+for+rule+extraction+in+classification+problems.+Neural+Process.+Lett.+35%2C+2+%282012%29%2C+131%2D%2D150.+10.1007%2Fs11063-011-9207-8+
http://scholar.google.com/scholar?hl=en&q=Sebastian+Bach%2C+Alexander+Binder%2C+Gr%C3%A9goire+Montavon%2C+Frederick+Klauschen%2C+Klaus-Robert+M%C3%BCller%2C+and+Wojciech+Samek.+2015.+On+pixel-wise+explanations+for+non-linear+classifier+decisions+by+layer-wise+relevance+propagation.+PloS+One+10%2C+7+%282015%29%2C+e0130140.
http://scholar.google.com/scholar?hl=en&q=David+Baehrens%2C+Timon+Schroeter%2C+Stefan+Harmeling%2C+Motoaki+Kawanabe%2C+Katja+Hansen%2C+and+Klaus-Robert+M%C3%83%C5%BEller.+2010.+How+to+explain+individual+classification+decisions.+J.+Mach.+Learn.+Res.+11%28June+2010%29%2C+1803%2D%2D1831.+
http://scholar.google.com/scholar?hl=en&q=Jacob+Bien+and+Robert+Tibshirani.+2011.+Prototype+selection+for+interpretable+classification.+Ann.+Appl.+Stat.+5%2C+4+%282011%29%2C+2403%2D%2D2424.
http://scholar.google.com/scholar?hl=en&q=Marko+Bohanec+and+Ivan+Bratko.+1994.+Trading+accuracy+for+simplicity+in+decision+trees.+Mach.+Learn.+15%2C+3+%281994%29%2C+223%2D%2D250.+10.1023%2FA%3A1022685808937+
http://scholar.google.com/scholar?hl=en&q=Mariusz+Bojarski%2C+Anna+Choromanska%2C+Krzysztof+Choromanski%2C+Bernhard+Firner%2C+Larry+Jackel%2C+Urs+Muller%2C+and+Karol+Zieba.+2016.+VisualBackProp%3A+Visualizing+CNNs+for+autonomous+driving.+CoRR%2C+Vol.+abs%2F1611.05418+%282016%29.
http://scholar.google.com/scholar?hl=en&q=Olcay+Boz.+2002.+Extracting+decision+trees+from+trained+neural+networks.+In+Proceedings+of+the+8th+ACM+SIGKDD+International+Conference+on+Knowledge+Discovery+and+Data+Mining.+ACM%2C+456%2D%2D461.+10.1145%2F775047.775113+
http://scholar.google.com/scholar?hl=en&q=Leo+Breiman%2C+Jerome+Friedman%2C+Charles+J.+Stone%2C+and+Richard+A.+Olshen.+1984.+Classification+and+Regression+Trees.+CRC+Press.
http://scholar.google.com/scholar?hl=en&q=Aylin+Caliskan-Islam%2C+Joanna+J.+Bryson%2C+and+Arvind+Narayanan.+2016.+Semantics+derived+automatically+from+language+corpora+necessarily+contain+human+biases.+arXiv+preprint+arXiv%3A1608.07187+%282016%29.
http://scholar.google.com/scholar?hl=en&q=Carolyn+Carter%2C+Elizabeth+Renuart%2C+Margot+Saunders%2C+and+Chi+Chi+Wu.+2006.+The+credit+card+market+and+regulation%3A+In+need+of+repair.+NC+Bank.+Inst.+10+%282006%29%2C+23.
http://scholar.google.com/scholar?hl=en&q=Rich+Caruana%2C+Yin+Lou%2C+Johannes+Gehrke%2C+Paul+Koch%2C+Marc+Sturm%2C+and+Noemie+Elhadad.+2015.+Intelligible+models+for+healthcare%3A+Predicting+pneumonia+risk+and+hospital+30-day+readmission.+In+Proceedings+of+the+21st+ACM+SIGKDD+International+Conference+on+Knowledge+Discovery+and+Data+Mining.+ACM%2C+1721%2D%2D1730.+10.1145%2F2783258.2788613+
http://scholar.google.com/scholar?hl=en&q=H.+A.+Chipman%2C+E.+I.+George%2C+and+R.+E.+McCulloh.+1998.+Making+sense+of+a+forest+of+trees.+In+Proceedings+of+the+30th+Symposium+on+the+Interface%2C+S.+Weisberg+%28Ed.%29.+Fairfax+Station%2C+VA%3A+Interface+Foundation+of+North+America%2C+84%2D%2D92.
http://scholar.google.com/scholar?hl=en&q=Paulo+Cortez+and+Mark+J.+Embrechts.+2011.+Opening+black+box+data+mining+models+using+sensitivity+analysis.+In+Proceedings+of+the+IEEE+Symposium+on+Computational+Intelligence+and+Data+Mining+%28CIDM%E2%80%9911%29.+IEEE%2C+341%2D%2D348.
http://scholar.google.com/scholar?hl=en&q=Paulo+Cortez+and+Mark+J.+Embrechts.+2013.+Using+sensitivity+analysis+and+visualization+techniques+to+open+black+box+data+mining+models.+Info.+Sci.+225+%282013%29%2C+1%2D%2D17.+10.1016%2Fj.ins.2012.10.039+
http://scholar.google.com/scholar?hl=en&q=Paulo+Cortez%2C+Juliana+Teixeira%2C+Ant%C3%B3nio+Cerdeira%2C+Fernando+Almeida%2C+Telmo+Matos%2C+and+Jos%C3%A9+Reis.+2009.+Using+data+mining+for+wine+quality+assessment.+In+Discovery+Science%2C+Vol.+5808.+Springer%2C+66%2D%2D79.+10.1007%2F978-3-642-04747-3_8+
http://scholar.google.com/scholar?hl=en&q=Mark+Craven+and+Jude+W.+Shavlik.+1994.+Using+sampling+and+queries+to+extract+rules+from+trained+neural+networks.+In+Proceedings+of+the+International+Conference+on+Machine+Learning+%28ICML%E2%80%9994%29.+37%2D%2D45.+
http://scholar.google.com/scholar?hl=en&q=Mark+Craven+and+Jude+W.+Shavlik.+1996.+Extracting+tree-structured+representations+of+trained+networks.+In+Proceedings+of+the+Conference+on+Advances+in+Neural+Information+Processing+Systems.+24%2D%2D30.+
http://scholar.google.com/scholar?hl=en&q=David+Danks+and+Alex+John+London.+2017.+Regulating+autonomous+systems%3A+Beyond+standards.+IEEE+Intell.+Syst.+32%2C+1+%282017%29%2C+88%2D%2D91.+10.1109%2FMIS.2017.1+
http://scholar.google.com/scholar?hl=en&q=Anupam+Datta%2C+Shayak+Sen%2C+and+Yair+Zick.+2016.+Algorithmic+transparency+via+quantitative+input+influence%3A+Theory+and+experiments+with+learning+systems.+In+Proceedings+of+the+IEEE+Symposium+on+Security+and+Privacy+%28SP%E2%80%9916%29.+IEEE%2C+598%2D%2D617.
http://scholar.google.com/scholar?hl=en&q=Houtao+Deng.+2014.+Interpreting+tree+ensembles+with+intrees.+arXiv+preprint+arXiv%3A1408.5456+%282014%29.
http://scholar.google.com/scholar?hl=en&q=Pedro+Domingos.+1998.+Knowledge+discovery+via+multiple+models.+Intell.+Data+Anal.+2%2C+1%2D%2D4+%281998%29%2C+187%2D%2D202.+
http://scholar.google.com/scholar?hl=en&q=Pedro+Domingos.+1998.+Occam%E2%80%99s+two+razors%3A+The+sharp+and+the+blunt.+In+Proceedings+of+the+International+Conference+on+Knowledge+Discovery+and+Data+Mining+%28KDD%E2%80%9998%29.+37%2D%2D43.+
http://scholar.google.com/scholar?hl=en&q=Finale+Doshi-Velez+and+Been+Kim.+2017.+Towards+a+rigorous+science+of+interpretable+machine+learning.+arXiv%3A1702.08608v2.
http://scholar.google.com/scholar?hl=en&q=Strumbelj+Erik+and+Igor+Kononenko.+2010.+An+efficient+explanation+of+individual+classifications+using+game+theory.+J.+Mach.+Learn.+Res.+11%28Jan.+2010%29%2C+1%2D%2D18.+
http://scholar.google.com/scholar?hl=en&q=Ruth+Fong+and+Andrea+Vedaldi.+2017.+Interpretable+explanations+of+black+boxes+by+meaningful+perturbation.+arXiv+preprint+arXiv%3A1704.03296+%282017%29.
http://scholar.google.com/scholar?hl=en&q=Eibe+Frank+and+Ian+H.+Witten.+1998.+Generating+accurate+rule+sets+without+global+optimization.+In+Proceedings+of+the+Fifteenth+International+Conference+on+Machine+Learning+%28ICML%2798%29.+144%2D%2D151.+
http://scholar.google.com/scholar?hl=en&q=Alex+A.+Freitas.+2014.+Comprehensible+classification+models%3A+A+position+paper.+ACM+SIGKDD+Explor.+Newslett.+15%2C+1+%282014%29%2C+1%2D%2D10.+10.1145%2F2594473.2594475+
http://scholar.google.com/scholar?hl=en&q=Glenn+Fung%2C+Sathyakama+Sandilya%2C+and+R.+Bharat+Rao.+2005.+Rule+extraction+from+linear+support+vector+machines.+In+Proceedings+of+the+11th+ACM+SIGKDD+International+Conference+on+Knowledge+Discovery+in+Data+Mining.+ACM%2C+32%2D%2D40.+10.1145%2F1081870.1081878+
http://scholar.google.com/scholar?hl=en&q=Robert+D.+Gibbons%2C+Giles+Hooker%2C+Matthew+D.+Finkelman%2C+David+J.+Weiss%2C+Paul+A.+Pilkonis%2C+Ellen+Frank%2C+Tara+Moore%2C+and+David+J.+Kupfer.+2013.+The+CAD-MDD%3A+A+computerized+adaptive+diagnostic+screening+tool+for+depression.+J.+Clin.+Psych.+74%2C+7+%282013%29%2C+669.
http://scholar.google.com/scholar?hl=en&q=Alex+Goldstein%2C+Adam+Kapelner%2C+Justin+Bleich%2C+and+Emil+Pitkin.+2015.+Peeking+inside+the+black+box%3A+Visualizing+statistical+learning+with+plots+of+individual+conditional+expectation.+J.+Comput.+Graph.+Stat.+24%2C+1+%282015%29%2C+44%2D%2D65.
http://scholar.google.com/scholar?hl=en&q=Bryce+Goodman+and+Seth+Flaxman.+2016.+EU+regulations+on+algorithmic+decision-making+and+a+%E2%80%9Cright+to+explanation.%E2%80%9D+In+Proceedings+of+the+ICML+Workshop+on+Human+Interpretability+in+Machine+Learning+%28WHI%E2%80%9916%29.+Retrieved+from+http%3A%2F%2Farxiv.+org%2Fabs%2F1606.08813+v1.
http://scholar.google.com/scholar?hl=en&q=Riccardo+Guidotti%2C+Anna+Monreale%2C+Salvatore+Ruggieri%2C+Dino+Pedreschi%2C+Franco+Turini%2C+and+Fosca+Giannotti.+2018.+Local+rule-based+explanations+of+black+box+decision+systems.+arXiv+preprint+arXiv%3A1805.10820+%282018%29.
http://scholar.google.com/scholar?hl=en&q=Satoshi+Hara+and+Kohei+Hayashi.+2016.+Making+tree+ensembles+interpretable.+arXiv+preprint+arXiv%3A1606.05390+%282016%29.
http://scholar.google.com/scholar?hl=en&q=Stefan+Haufe%2C+Frank+Meinecke%2C+Kai+G%C3%B6rgen%2C+Sven+D%C3%A4hne%2C+John-Dylan+Haynes%2C+Benjamin+Blankertz%2C+and+Felix+Bie%C3%9Fmann.+2014.+On+the+interpretation+of+weight+vectors+of+linear+models+in+multivariate+neuroimaging.+Neuroimage+87+%282014%29%2C+96%2D%2D110.
http://scholar.google.com/scholar?hl=en&q=Andreas+Henelius%2C+Kai+Puolam%C3%A4ki%2C+Henrik+Bostr%C3%B6m%2C+Lars+Asker%2C+and+Panagiotis+Papapetrou.+2014.+A+peek+into+the+black+box%3A+Exploring+classifiers+by+randomization.+Data+Min.+Knowl.+Discov.+28%2C+5%2D%2D6+%282014%29%2C+1503%2D%2D1529.+10.1007%2Fs10618-014-0368-8+
http://scholar.google.com/scholar?hl=en&q=Jake+M.+Hofman%2C+Amit+Sharma%2C+and+Duncan+J.+Watts.+2017.+Prediction+and+explanation+in+social+systems.+Science+355%2C+6324+%282017%29%2C+486%2D%2D488.
http://scholar.google.com/scholar?hl=en&q=Giles+Hooker.+2004.+Discovering+additive+structure+in+black+box+functions.+In+Proceedings+of+the+10th+ACM+SIGKDD+International+Conference+on+Knowledge+Discovery+and+Data+Mining.+ACM%2C+575%2D%2D580.+10.1145%2F1014052.1014122+
http://scholar.google.com/scholar?hl=en&q=Johan+Huysmans%2C+Karel+Dejaeger%2C+Christophe+Mues%2C+Jan+Vanthienen%2C+and+Bart+Baesens.+2011.+An+empirical+evaluation+of+the+comprehensibility+of+decision+table%2C+tree+and+rule+based+predictive+models.+Decis.+Supp.+Syst.+51%2C+1+%282011%29%2C+141%2D%2D154.+10.1016%2Fj.dss.2010.12.003+
http://scholar.google.com/scholar?hl=en&q=U.+Johansson%2C+R.+K%C3%B6nig%2C+and+L.+Niklasson.+2003.+Rule+extraction+from+trained+neural+networks+using+genetic+programming.+In+Proceedings+of+the+13th+International+Conference+on+Artificial+Neural+Networks.+13%2D%2D16.
http://scholar.google.com/scholar?hl=en&q=Ulf+Johansson%2C+Rikard+K%C3%B6nig%2C+and+Lars+Niklasson.+2004.+The+truth+is+in+there-rule+extraction+from+opaque+models+using+genetic+programming.+In+Proceedings+of+the+FLAIRS+Conference.+658%2D%2D663.
http://scholar.google.com/scholar?hl=en&q=Ulf+Johansson+and+Lars+Niklasson.+2009.+Evolving+decision+trees+using+oracle+guides.+In+Proceedings+of+the+IEEE+Symposium+on+Computational+Intelligence+and+Data+Mining+%28CIDM%E2%80%9909%29.+IEEE%2C+238%2D%2D244.
http://scholar.google.com/scholar?hl=en&q=Ulf+Johansson%2C+Lars+Niklasson%2C+and+Rikard+K%C3%B6nig.+2004.+Accuracy+vs.+comprehensibility+in+data+mining+models.+In+Proceedings+of+the+7th+International+Conference+on+Information+Fusion%2C+Vol.+1.+295%2D%2D300.
http://scholar.google.com/scholar?hl=en&q=Hiroharu+Kato+and+Tatsuya+Harada.+2014.+Image+reconstruction+from+bag-of-visual-words.+In+Proceedings+of+the+IEEE+Conference+on+Computer+Vision+and+Pattern+Recognition.+955%2D%2D962.+10.1109%2FCVPR.2014.127+
http://scholar.google.com/scholar?hl=en&q=Been+Kim%2C+Elena+Glassman%2C+Brittney+Johnson%2C+and+Julie+Shah.+2015.+iBCM%3A+Interactive+Bayesian+case+model+empowering+humans+via+intuitive+interaction.+Technical+Report%3A+MIT-CSAIL-TR-2015-010.
http://scholar.google.com/scholar?hl=en&q=Been+Kim%2C+Oluwasanmi+O.+Koyejo%2C+and+Rajiv+Khanna.+2016.+Examples+are+not+enough%2C+learn+to+criticize%26excl%3B+criticism+for+interpretability.+In+Proceedings+of+the+Conference+on+Advances+in+Neural+Information+Processing+Systems.+2280%2D%2D2288.+
http://scholar.google.com/scholar?hl=en&q=Been+Kim%2C+Cynthia+Rudin%2C+and+Julie+A.+Shah.+2014.+The+Bayesian+case+model%3A+A+generative+approach+for+case-based+reasoning+and+prototype+classification.+In+Proceedings+of+the+Conference+on+Advances+in+Neural+Information+Processing+Systems.+1952%2D%2D1960.+
http://scholar.google.com/scholar?hl=en&q=Been+Kim%2C+Julie+A.+Shah%2C+and+Finale+Doshi-Velez.+2015.+Mind+the+gap%3A+A+generative+approach+to+interpretable+feature+selection+and+extraction.+In+Proceedings+of+the+Conference+on+Advances+in+Neural+Information+Processing+Systems.+2260%2D%2D2268.+
http://scholar.google.com/scholar?hl=en&q=John+K.+C.+Kingston.+2016.+Artificial+intelligence+and+legal+liability.+In+Proceedings+of+the+Specialist+Group+on+Artificial+Intelligence+Conference+%28SGAI%E2%80%9916%29.+Springer%2C+269%2D%2D279.
http://scholar.google.com/scholar?hl=en&q=Pang+Wei+Koh+and+Percy+Liang.+2017.+Understanding+black-box+predictions+via+influence+functions.+arXiv+preprint+arXiv%3A1703.04730+%282017%29.
http://scholar.google.com/scholar?hl=en&q=Josua+Krause%2C+Adam+Perer%2C+and+Kenney+Ng.+2016.+Interacting+with+predictions%3A+Visual+inspection+of+black-box+machine+learning+models.+In+Proceedings+of+the+CHI+Conference+on+Human+Factors+in+Computing+Systems.+ACM%2C+5686%2D%2D5697.+10.1145%2F2858036.2858529+
http://scholar.google.com/scholar?hl=en&q=Samantha+Krening%2C+Brent+Harrison%2C+Karen+M.+Feigh%2C+Charles+Lee+Isbell%2C+Mark+Riedl%2C+and+Andrea+Thomaz.+2017.+Learning+from+explanations+using+sentiment+and+advice+in+RL.+IEEE+Trans.+Cogn.+Dev.+Syst.+9%2C+1+%282017%29%2C+44%2D%2D55.
http://scholar.google.com/scholar?hl=en&q=R.+Krishnan%2C+G.+Sivakumar%2C+and+P.+Bhattacharya.+1999.+Extracting+decision+trees+from+trained+neural+networks.+Pattern+Recogn.+32%2C+12+%281999%29.
http://scholar.google.com/scholar?hl=en&q=Sanjay+Krishnan+and+Eugene+Wu.+2017.+PALM%3A+Machine+learning+explanations+for+iterative+debugging.+In+Proceedings+of+the+2nd+Workshop+on+Human-In-the-Loop+Data+Analytics.+ACM%2C+4.+10.1145%2F3077257.3077271+
http://scholar.google.com/scholar?hl=en&q=Joshua+A.+Kroll%2C+Joanna+Huey%2C+Solon+Barocas%2C+Edward+W.+Felten%2C+Joel+R.+Reidenberg%2C+David+G.+Robinson%2C+and+Harlan+Yu.+2017.+Accountable+algorithms.+U.+Penn.+Law+Rev.+165+%282017%29%2C+633%2D%2D705.
http://scholar.google.com/scholar?hl=en&q=Alexey+Kurakin%2C+Ian+Goodfellow%2C+and+Samy+Bengio.+2016.+Adversarial+examples+in+the+physical+world.+arXiv+preprint+arXiv%3A1607.02533+%282016%29.
http://scholar.google.com/scholar?hl=en&q=Himabindu+Lakkaraju%2C+Stephen+H.+Bach%2C+and+Jure+Leskovec.+2016.+Interpretable+decision+sets%3A+A+joint+framework+for+description+and+prediction.+In+Proceedings+of+the+22nd+ACM+SIGKDD+International+Conference+on+Knowledge+Discovery+and+Data+Mining.+ACM%2C+1675%2D%2D1684.+10.1145%2F2939672.2939874+
http://scholar.google.com/scholar?hl=en&q=Himabindu+Lakkaraju%2C+Ece+Kamar%2C+Rich+Caruana%2C+and+Jure+Leskovec.+2017.+Interpretable+8+explorable+approximations+of+black+box+models.+arXiv+preprint+arXiv%3A1707.01154+%282017%29.
http://scholar.google.com/scholar?hl=en&q=Himabindu+Lakkaraju%2C+Jon+Kleinberg%2C+Jure+Leskovec%2C+Jens+Ludwig%2C+and+Sendhil+Mullainathan.+2017.+The+selective+labels+problem%3A+Evaluating+algorithmic+predictions+in+the+presence+of+unobservables.+In+Proceedings+of+the+23rd+ACM+SIGKDD+International+Conference+on+Knowledge+Discovery+and+Data+Mining.+ACM%2C+275%2D%2D284.+10.1145%2F3097983.3098066+
http://scholar.google.com/scholar?hl=en&q=Will+Landecker%2C+Michael+D.+Thomure%2C+Lu%C3%ADs+M.+A.+Bettencourt%2C+Melanie+Mitchell%2C+Garrett+T.+Kenyon%2C+and+Steven+P.+Brumby.+2013.+Interpreting+individual+classifications+of+hierarchical+networks.+In+Proceedings+of+the+IEEE+Symposium+on+Computational+Intelligence+and+Data+Mining+%28CIDM%E2%80%9913%29.+IEEE%2C+32%2D%2D38.
http://scholar.google.com/scholar?hl=en&q=Tao+Lei%2C+Regina+Barzilay%2C+and+Tommi+Jaakkola.+2016.+Rationalizing+neural+predictions.+arXiv+preprint+arXiv%3A1606.04155+%282016%29.
http://scholar.google.com/scholar?hl=en&q=Benjamin+Letham%2C+Cynthia+Rudin%2C+Tyler+H.+McCormick%2C+David+Madigan+et+al.+2015.+Interpretable+classifiers+using+rules+and+Bayesian+analysis%3A+Building+a+better+stroke+prediction+model.+Ann.+Appl.+Stat.+9%2C+3+%282015%29%2C+1350%2D%2D1371.
http://scholar.google.com/scholar?hl=en&q=Bin+Liang%2C+Hongcheng+Li%2C+Miaoqiang+Su%2C+Pan+Bian%2C+Xirong+Li%2C+and+Wenchang+Shi.+2017.+Deep+text+classification+can+be+fooled.+arXiv+preprint+arXiv%3A1704.08006+%282017%29.
http://scholar.google.com/scholar?hl=en&q=Zachary+C.+Lipton.+2016.+The+mythos+of+model+interpretability.+arXiv+preprint+arXiv%3A1606.03490+%282016%29.
http://scholar.google.com/scholar?hl=en&q=Yin+Lou%2C+Rich+Caruana%2C+and+Johannes+Gehrke.+2012.+Intelligible+models+for+classification+and+regression.+In+Proceedings+of+the+18th+ACM+SIGKDD+International+Conference+on+Knowledge+Discovery+and+Data+Mining.+ACM%2C+150%2D%2D158.+10.1145%2F2339530.2339556+
http://scholar.google.com/scholar?hl=en&q=Yin+Lou%2C+Rich+Caruana%2C+Johannes+Gehrke%2C+and+Giles+Hooker.+2013.+Accurate+intelligible+models+with+pairwise+interactions.+In+Proceedings+of+the+19th+ACM+SIGKDD+International+Conference+on+Knowledge+Discovery+and+Data+Mining.+ACM%2C+623%2D%2D631.+10.1145%2F2487575.2487579+
http://scholar.google.com/scholar?hl=en&q=Stella+Lowry+and+Gordon+Macpherson.+1988.+A+blot+on+the+profession.+Brit.+Med.+J.+Clin.+Res.+296%2C+6623+%281988%29%2C+657.
