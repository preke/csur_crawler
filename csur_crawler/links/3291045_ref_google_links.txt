http://scholar.google.com/scholar?hl=en&q=Pierre-Luc+Bacon%2C+Jean+Harb%2C+and+Doina+Precup.+2017.+The+option-critic+architecture.+In+Proceedings+of+the+AAAI+Conference+on+Artificial+Intelligence.+1726%2D%2D1734.+
http://scholar.google.com/scholar?hl=en&q=Pierre-Luc+Bacon+and+Doina+Precup.+2013.+Using+label+propagation+for+learning+temporally+abstract+actions+in+reinforcement+learning.+In+Proceedings+of+the+Workshop+on+Multiagent+Interaction+Networks.+1%2D%2D7.
http://scholar.google.com/scholar?hl=en&q=Albert-L%C3%A1szl%C3%B3+Barab%C3%A1si.+2016.+Network+Science.+Cambridge+University+Press.
http://scholar.google.com/scholar?hl=en&q=Andre+Barreto%2C+Will+Dabney%2C+Remi+Munos%2C+Jonathan+J.+Hunt%2C+Tom+Schaul%2C+David+Silver%2C+and+Hado+P.+van+Hasselt.+2017.+Successor+features+for+transfer+in+reinforcement+learning.+In+Advances+in+Neural+Information+Processing+Systems+%28NIPS%E2%80%9917%29.+Curran+Associates%2C+4058%2D%2D4068.+
http://scholar.google.com/scholar?hl=en&q=Charles+Beattie%2C+Joel+Z.+Leibo%2C+Denis+Teplyashin%2C+Tom+Ward%2C+Marcus+Wainwright%2C+Heinrich+K%C3%BCttler%2C+Andrew+Lefrancq%2C+Simon+Green%2C+V%C3%ADctor+Vald%C3%A9s%2C+Amir+Sadik%2C+Julian+Schrittwieser%2C+Keith+Anderson%2C+Sarah+York%2C+Max+Cant%2C+Adam+Cain%2C+Adrian+Bolton%2C+Stephen+Gaffney%2C+Helen+King%2C+Demis+Hassabis%2C+Shane+Legg%2C+and+Stig+Petersen.+2016.+DeepMind+lab.+arXiv+preprint+arXiv%3A1612.03801+%282016%29.
http://scholar.google.com/scholar?hl=en&q=Marc+G.+Bellemare%2C+Yavar+Naddaf%2C+Joel+Veness%2C+and+Michael+Bowling.+2013.+The+arcade+learning+environment%3A+An+evaluation+platform+for+general+agents.+Journal+of+Artificial+Intelligence+Research+47%2C+1+%28May+2013%29%2C+253%2D%2D279.+
http://scholar.google.com/scholar?hl=en&q=Katy+B%C3%B6rner%2C+Soma+Sanyal%2C+and+Alessandro+Vespignani.+2007.+Network+science.+Annual+Review+of+Information+Science+and+Technology+41%2C+1+%282007%29%2C+537%2D%2D607.+
http://scholar.google.com/scholar?hl=en&q=Greg+Brockman%2C+Vicki+Cheung%2C+Ludwig+Pettersson%2C+Jonas+Schneider%2C+John+Schulman%2C+Jie+Tang%2C+and+Wojciech+Zaremba.+2016.+OpenAI+gym.+arXiv+preprint+arXiv%3A1606.01540+%282016%29.
http://scholar.google.com/scholar?hl=en&q=Fei+Chen%2C+Yang+Gao%2C+Shifu+Chen%2C+and+Zhenduo+Ma.+2007.+Connect-based+subgoal+discovery+for+options+in+hierarchical+reinforcement+learning.+In+Proceedings+of+the+International+Conference+on+Natural+Computation+%28ICNC%E2%80%9907%29%2C+Vol.+4.+698%2D%2D702.+10.1109%2FICNC.2007.312+
http://scholar.google.com/scholar?hl=en&q=Cc+Chiu+and+Von-Wun+Soo.+2011.+Subgoal+identifications+in+reinforcement+learning%3A+A+survey.+Advances+in+Reinforcement+Learning+%282011%29%2C+181%2D%2D188.
http://scholar.google.com/scholar?hl=en&q=Ozg%C3%BCr+%C5%9Eim%C5%9Fek.+2008.+Behavioral+Building+Blocks+for+Autonomous+Agents%3A+Description%2C+Identification%2C+and+Learning.+Ph.D.+Dissertation.+University+of+Massachusetts.
http://scholar.google.com/scholar?hl=en&q=Ozg%C3%BCr+%C5%9Eim%C5%9Fek+and+A.+Barto.+2007.+Betweenness+centrality+as+a+basis+for+forming+skills.+Technical+Report%2C+University+of+Massachusetts%2C+Department+of+Computer+Science.
http://scholar.google.com/scholar?hl=en&q=%C3%96zg%C3%BCr+%C5%9Eim%C5%9Fek+and+Andrew+G.+Barto.+2004.+Using+relative+novelty+to+identify+useful+temporal+abstractions+in+reinforcement+learning.+In+Proceedings+of+the+International+Conference+on+Machine+Learning+%28ICML%E2%80%9904%29.+ACM%2C+New+York%2C+95%2D%2D103.+10.1145%2F1015330.1015353+
http://scholar.google.com/scholar?hl=en&q=Ozg%C3%BCr+%C5%9Eim%C5%9Fek+and+Andrew+G.+Barto.+2008.+Skill+characterization+based+on+betweenness.+In+Advances+in+Neural+Information+Processing+Systems+%28NIPS%E2%80%9908%29%2C+1497%2D%2D1504.+
http://scholar.google.com/scholar?hl=en&q=%C3%96zg%C3%BCr+%C5%9Eim%C5%9Fek%2C+Alicia+P.+Wolfe%2C+and+Andrew+G.+Barto.+2005.+Identifying+useful+subgoals+in+reinforcement+learning+by+local+graph+partitioning.+In+Proceedings+of+the+International+Conference+on+Machine+Learning+%28ICML%E2%80%9905%29.+ACM%2C+New+York%2C+816%2D%2D823.+10.1145%2F1102351.1102454+
http://scholar.google.com/scholar?hl=en&q=Marzieh+Davoodabadi+and+Hamid+Beigy.+2011.+A+new+method+for+discovering+subgoals+and+constructing+options+in+reinforcement+learning.+In+Indian+International+Conference+on+Artificial+Intelligence+%28IICAI%E2%80%9911%29.+441%2D%2D450.
http://scholar.google.com/scholar?hl=en&q=Peter+Dayan.+1993.+Improving+generalization+for+temporal+difference+learning%3A+The+successor+representation.+Neural+Computation+5%2C+4+%281993%29%2C+613%2D%2D624.+10.1162%2Fneco.1993.5.4.613+
http://scholar.google.com/scholar?hl=en&q=Thomas+G.+Dietterich.+2000.+Hierarchical+reinforcement+learning+with+the+MAXQ+value+function+decomposition.+Journal+of+Artificial+Intelligence+Research+13%2C+1+%28Nov.+2000%29%2C+227%2D%2D303.+
http://scholar.google.com/scholar?hl=en&q=Bruce+L.+Digney.+1998.+Learning+hierarchical+control+structures+for+multiple+tasks+and+changing+environments.+From+Animals+to+Animats+5%3A+Proceedings+of+the+International+Conference+on+the+Simulation+of+Adaptive+Behavior.+321%2D%2D330.+
http://scholar.google.com/scholar?hl=en&q=Yan+Duan%2C+Xi+Chen%2C+Rein+Houthooft%2C+John+Schulman%2C+and+Pieter+Abbeel.+2016.+Benchmarking+deep+reinforcement+learning+for+continuous+control.+In+Proceedings+of+the+International+Conference+on+International+Conference+on+Machine+Learning+%28ICML%E2%80%9916%29%2C+Vol.+48.+1329%2D%2D1338.+
http://scholar.google.com/scholar?hl=en&q=Negin+Entezari%2C+Mohammad+Ebrahim+Shiri%2C+and+Parham+Moradi.+2010.+A+local+graph+clustering+algorithm+for+discovering+subgoals+in+reinforcement+learning.+In+Communications+in+Computer+and+Information+Science.+Springer%2C+Berlin%2C+41%2D%2D50.
http://scholar.google.com/scholar?hl=en&q=Sandeep+Goel+and+Manfred+Huber.+2003.+Subgoal+discovery+for+hierarchical+reinforcement+learning+using+learned+policies.+In+Proceedings+of+the+International+Florida+Artificial+Intelligence+Research+Society+Conference%2C+Ingrid+Russell+and+Susan+M.+Haller+%28Eds.%29.+AAAI+Press%2C+346%2D%2D350.
http://scholar.google.com/scholar?hl=en&q=Ian+Goodfellow%2C+Jean+Pouget-Abadie%2C+Mehdi+Mirza%2C+Bing+Xu%2C+David+Warde-Farley%2C+Sherjil+Ozair%2C+Aaron+Courville%2C+and+Yoshua+Bengio.+2014.+Generative+adversarial+nets.+In+Advances+in+Neural+Information+Processing+Systems+%28NIPS%E2%80%9914%29.+Curran+Associates%2C+2672%2D%2D2680.+
http://scholar.google.com/scholar?hl=en&q=Karol+Gregor%2C+Ivo+Danihelka%2C+Alex+Graves%2C+Danilo+Rezende%2C+and+Daan+Wierstra.+2015.+DRAW%3A+A+recurrent+neural+network+for+image+generation.+In+Proceedings+of+the+International+Conference+on+Machine+Learning+%28Proceedings+of+Machine+Learning+Research%29%2C+Francis+Bach+and+David+Blei+%28Eds.%29%2C+Vol.+37.+PMLR%2C+Lille%2C+France%2C+1462%2D%2D1471.+
http://scholar.google.com/scholar?hl=en&q=Bernhard+Hengst.+2002.+Discovering+hierarchy+in+reinforcement+learning+with+HEXQ.+In+Proceedings+of+the+International+Conference+on+Machine+Learning+%28ICML%E2%80%9902%29.+Morgan+Kaufmann+Publishers%2C+San+Francisco%2C+243%2D%2D250.+
http://scholar.google.com/scholar?hl=en&q=Bernhard+Hengst.+2003.+Discovering+Hierarchy+in+Reinforcement+Learning.+Ph.D.+Dissertation.+University+of+New+South+Wales.+
http://scholar.google.com/scholar?hl=en&q=Bernhard+Hengst.+2004.+Model+approximation+for+HEXQ+hierarchical+reinforcement+learning.+In+Proceedings+of+the+European+Conference+on+Machine+Learning+%28ECML%E2%80%9904%29.+Springer%2C+Berlin%2C144%2D%2D155.+10.1007%2F978-3-540-30115-8_16+
http://scholar.google.com/scholar?hl=en&q=Alexandru+Iosup%2C+Tim+Hegeman%2C+Wing+Lung+Ngai%2C+Stijn+Heldens%2C+Arnau+Prat-P%C3%A9rez%2C+Thomas+Manhardto%2C+Hassan+Chafio%2C+Mihai+Capot%C4%83%2C+Narayanan+Sundaram%2C+Michael+Anderson%2C+Ilie+Gabriel+T%C4%83nase%2C+Yinglong+Xia%2C+Lifeng+Nai%2C+and+Peter+Boncz.+2016.+LDBC+graphalytics%3A+A+benchmark+for+large-scale+graph+analysis+on+parallel+and+distributed+platforms.+Proceedings+of+the+VLDB+Endowment+9%2C+13+%282016%29%2C+1317%2D%2D1328.+10.14778%2F3007263.3007270+
http://scholar.google.com/scholar?hl=en&q=Andrej+Karpathy+and+Li+Fei-Fei.+2017.+Deep+visual-semantic+alignments+for+generating+image+descriptions.+IEEE+Transactions+on+Pattern+Analysis+and+Machine+Intelligence+39%2C+4+%282017%29%2C+664%2D%2D676.+10.1109%2FTPAMI.2016.2598339+
http://scholar.google.com/scholar?hl=en&q=Seyed+Jalal+Kazemitabar+and+Hamid+Beigy.+2009.+Using+strongly+connected+components+as+a+basis+for+autonomous+skill+acquisition+in+reinforcement+learning.+In+Proceedings+of+the+International+Symposium+on+Neural+Networks+%28ISNN%E2%80%9909%29.+Springer%2C+Berlin%2C+794%2D%2D803.+10.1007%2F978-3-642-01507-6_89+
http://scholar.google.com/scholar?hl=en&q=Ghorban+Kheradmandian+and+Mohammad+Rahmati.+2009.+Automatic+abstraction+in+reinforcement+learning+using+data+mining+techniques.+Robotics+and+Autonomous+Systems+57%2C+11+%282009%29%2C+1119%2D%2D1128.+10.1016%2Fj.robot.2009.07.002+
http://scholar.google.com/scholar?hl=en&q=George+Konidaris+and+Andrew+Barto.+2009.+Skill+discovery+in+continuous+reinforcement+learning+domains+using+skill+chaining.+In+Advances+in+Neural+Information+Processing+Systems+%28NIPS%E2%80%9909%29%2C+Y.+Bengio%2C+D.+Schuurmans%2C+J.+Lafferty%2C+C.+Williams%2C+and+A.+Culotta+%28Eds.%29.+1015%2D%2D1023.+
http://scholar.google.com/scholar?hl=en&q=Ramnandan+Krishnamurthy%2C+Aravind+S.+Lakshminarayanan%2C+Peeyush+Kumar%2C+and+Balaraman+Ravindran.+2016.+Hierarchical+reinforcement+learning+using+spatio-temporal+abstractions+and+deep+neural+networks.+In+Proceedings+of+the+International+Conference+on+Machine+Learning.
http://scholar.google.com/scholar?hl=en&q=Alex+Krizhevsky%2C+Ilya+Sutskever%2C+and+Geoffrey+E.+Hinton.+2012.+ImageNet+classification+with+deep+convolutional+neural+networks.+In+Advances+in+Neural+Information+Processing+Systems+%28NIPS%E2%80%9912%29.+Curran+Associates%2C+1097%2D%2D1105.+
http://scholar.google.com/scholar?hl=en&q=Long-Ji+Lin.+1992.+Self-improving+reactive+agents+based+on+reinforcement+learning%2C+planning+and+teaching.+Machine+Learning+8%2C+3+%281992%29%2C+293%2D%2D321.+10.1007%2FBF00992699+
http://scholar.google.com/scholar?hl=en&q=Yi+Lu%2C+James+Cheng%2C+Da+Yan%2C+and+Huanhuan+Wu.+2014.+Large-scale+distributed+graph+computing+systems%3A+An+experimental+evaluation.+Proceedings+of+the+VLDB+Endowment+8%2C+3%2C+281%2D%2D292.+10.14778%2F2735508.2735517+
http://scholar.google.com/scholar?hl=en&q=Marlos+C.+Machado%2C+Marc+G.+Bellemare%2C+and+Michael+H.+Bowling.+2017.+A+Laplacian+framework+for+option+discovery+in+reinforcement+learning.+In+Proceedings+of+the+International+Conference+on+Machine+Learning+%28ICML%E2%80%9917%29.+2295%2D%2D2304.+
http://scholar.google.com/scholar?hl=en&q=Marlos+C.+Machado%2C+Clemens+Rosenbaum%2C+Xiaoxiao+Guo%2C+Miao+Liu%2C+Gerald+Tesauro%2C+and+Murray+Campbell.+2017.+Eigenoption+discovery+through+the+deep+successor+representation.+CoRR+abs%2F1710.11089+%282017%29.+Retrieved+from+http%3A%2F%2Farxiv.org%2Fabs%2F1710.11089.
http://scholar.google.com/scholar?hl=en&q=Sridhar+Mahadevan.+2005.+Proto-value+functions%3A+Developmental+reinforcement+learning.+In+Proceedings+of+the+International+Conference+on+Machine+Learning+%28ICML%E2%80%9905%29.+ACM%2C+New+York%2C+553%2D%2D560.+10.1145%2F1102351.1102421+
http://scholar.google.com/scholar?hl=en&q=Grzegorz+Malewicz%2C+Matthew+H.+Austern%2C+and+Aart+J.+C.+Bik.+2010.+Pregel%3A+A+system+for+large-scale+graph+processing.+In+Proceedings+of+the+ACM+SIGMOD+International+Conference+on+Management+of+Data.+135%2D%2D145.+10.1145%2F1807167.1807184+
http://scholar.google.com/scholar?hl=en&q=Daniel+J.+Mankowitz%2C+Timothy+A.+Mann%2C+and+Shie+Mannor.+2016.+Adaptive+skills+adaptive+partitions+%28ASAP%29.+In+Advances+in+Neural+Information+Processing+Systems+%28NIPS%E2%80%9916%29%2C+D.+D.+Lee%2C+M.+Sugiyama%2C+U.+V.+Luxburg%2C+I.+Guyon%2C+and+R.+Garnett+%28Eds.%29.+Curran+Associates%2C+1588%2D%2D1596.+
http://scholar.google.com/scholar?hl=en&q=Shie+Mannor%2C+Ishai+Menache%2C+Amit+Hoze%2C+and+Uri+Klein.+2004.+Dynamic+abstraction+in+reinforcement+learning+via+clustering.+In+Proceedings+of+the+International+Conference+on+Machine+Learning+%28ICML%E2%80%9904%29.+ACM%2C+New+York%2C+71%2D%2D78.+10.1145%2F1015330.1015355+
http://scholar.google.com/scholar?hl=en&q=Oded+Maron.+1998.+Learning+from+Ambiguity.+Ph.D.+Dissertation.+Massachusetts+Institute+of+Technology.+
http://scholar.google.com/scholar?hl=en&q=Oded+Maron+and+Tom%C3%A1s+Lozano-P%C3%A9rez.+1998.+A+framework+for+multiple-instance+learning.+In+Proceedings+of+the+Conference+on+Advances+in+Neural+Information+Processing+Systems+%28NIPS%E2%80%9998%29.+MIT+Press%2C+Cambridge%2C+MA%2C+570%2D%2D576.+
http://scholar.google.com/scholar?hl=en&q=Vimal+Mathew%2C+Peeyush+Kumar%2C+and+Balaraman+Ravindran.+2012.+Abstraction+in+reinforcement+learning+in+terms+of+metastability.+In+Proceedings+of+the+European+Workshop+on+Reinforcement+Learning+%28EWRL%E2%80%9912%29.1%2D%2D14.
http://scholar.google.com/scholar?hl=en&q=Amy+McGovern+and+Andrew+G.+Barto.+2001.+Automatic+discovery+of+subgoals+in+reinforcement+learning+using+diverse+density.+In+Proceedings+of+the+International+Conference+on+Machine+Learning%2C+361%2D%2D368.+
http://scholar.google.com/scholar?hl=en&q=Amy+McGovern%2C+Richard+S.+Sutton%2C+and+Andrew+H.+Fagg.+1997.+Roles+of+macro-actions+in+accelerating+reinforcement+learning.+In+Grace+Hopper+Celebration+of+Women+in+Computing.+13%2D%2D18.
http://scholar.google.com/scholar?hl=en&q=Ishai+Menache%2C+Shie+Mannor%2C+and+Nahum+Shimkin.+2002.+Q-cut+-+dynamic+discovery+of+sub-goals+in+reinforcement+learning.+Proceedings+of+the+European+Conference+on+Machine+Learning%2C+295%2D%2D306.+
http://scholar.google.com/scholar?hl=en&q=Tom%C3%A1%C5%A1+Mikolov%2C+Stefan+Kombrink%2C+Luk%C3%A1%C5%A1+Burget%2C+Jan+%C4%8Cernock%C3%BD%2C+and+Sanjeev+Khudanpur.+2011.+Extensions+of+recurrent+neural+network+language+model.+In+IEEE+International+Conference+on+Acoustics%2C+Speech+and+Signal+Processing+%28ICASSP%E2%80%9911%29.+5528%2D%2D5531.
http://scholar.google.com/scholar?hl=en&q=Volodymyr+Mnih%2C+Adria+Puigdomenech+Badia%2C+Mehdi+Mirza%2C+Alex+Graves%2C+Timothy+Lillicrap%2C+Tim+Harley%2C+David+Silver%2C+and+Koray+Kavukcuoglu.+2016.+Asynchronous+methods+for+deep+reinforcement+learning.+In+Proceedings+of+the+International+Conference+on+Machine+Learning+%28Proceedings+of+Machine+Learning+Research%29%2C+Maria+Florina+Balcan+and+Kilian+Q.+Weinberger+%28Eds.%29%2C+Vol.+48.+PMLR%2C+New+York%2C+1928%2D%2D1937.+
http://scholar.google.com/scholar?hl=en&q=Volodymyr+Mnih%2C+Koray+Kavukcuoglu%2C+David+Silver%2C+Andrei+A.+Rusu%2C+Joel+Veness%2C+Marc+G.+Bellemare%2C+Alex+Graves%2C+Martin+Riedmiller%2C+Andreas+K.+Fidjeland%2C+Georg+Ostrovski%2C+Stig+Petersen%2C+Charles+Beattie%2C+Amir+Sadik%2C+Ioannis+Antonoglou%2C+Helen+King%2C+Dharshan+Kumaran%2C+Daan+Wierstra%2C+Shane+Legg%2C+and+Demis+Hassabis.+2015.+Human-level+control+through+deep+reinforcement+learning.+Nature+518%2C+7540+%28Feb.+2015%29%2C+529%2D%2D533.
http://scholar.google.com/scholar?hl=en&q=Bojan+Mohar.+1997.+Some+Applications+of+Laplace+Eigenvalues+of+Graphs.+Springer+Netherlands%2C+Dordrecht%2C+225%2D%2D275.
http://scholar.google.com/scholar?hl=en&q=Parham+Moradi%2C+Mohammad+Ebrahim+Shiri%2C+and+Negin+Entezari.+2010.+Automatic+skill+acquisition+in+reinforcement+learning+agents+using+connection+bridge+centrality.+In+Communications+in+Computer+and+Information+Science.+Springer%2C+Berlin%2C+51%2D%2D62.
http://scholar.google.com/scholar?hl=en&q=Mark+E.+J.+Newman+and+Michelle+Girvan.+2004.+Finding+and+evaluating+community+structure+in+networks.+Physical+Review+E+69%2C+2+%282004%29%2C+15.
http://scholar.google.com/scholar?hl=en&q=Junhyuk+Oh%2C+Xiaoxiao+Guo%2C+Honglak+Lee%2C+Richard+L.+Lewis%2C+and+Satinder+Singh.+2015.+Action-conditional+video+prediction+using+deep+networks+in+atari+games.+In+Advances+in+Neural+Information+Processing+Systems+%28NIPS%E2%80%9915%29%2C+C.+Cortes%2C+N.+D.+Lawrence%2C+D.+D.+Lee%2C+M.+Sugiyama%2C+and+R.+Garnett+%28Eds.%29.+Curran+Associates%2C+2863%2D%2D2871.+
http://scholar.google.com/scholar?hl=en&q=Sarah+Osentoski+and+Sridhar+Mahadevan.+2010.+Basis+function+construction+for+hierarchical+reinforcement+learning.+In+Proceedings+of+the+International+Conference+on+Autonomous+Agents+and+Multiagent+Systems+%28AAMAS%E2%80%9910%29.+International+Foundation+for+Autonomous+Agents+and+Multiagent+Systems%2C+Richland%2C+SC%2C+747%2D%2D754.+
http://scholar.google.com/scholar?hl=en&q=Ronald+Edward+Parr.+1998.+Hierarchical+Control+and+Learning+for+Markov+Decision+Processes.+Ph.D.+Dissertation.+University+of+California%2C+Berkeley.
http://scholar.google.com/scholar?hl=en&q=Duncan+Potts+and+Bernhard+Hengst.+2004.+Concurrent+discovery+of+task+hierarchies.+In+AAAI+Spring+Symposium+on+Knowledge+Representation+and+Ontology+for+Autonomous+Systems.+1%2D%2D8.
http://scholar.google.com/scholar?hl=en&q=Doina+Precup.+2000.+Temporal+Abstraction+in+Reinforcement+Learning.+Ph.D.+Dissertation.+University+of+Massachusetts.+
http://scholar.google.com/scholar?hl=en&q=Martin+L.+Puterman.+1994.+Markov+Decision+Processes%3A+Discrete+Stochastic+Dynamic+Programming.+John+Wiley+8+Sons.+
http://scholar.google.com/scholar?hl=en&q=Ali+Ajdari+Rad%2C+Martin+Hasler%2C+and+Parham+Moradi.+2010.+Automatic+skill+acquisition+in+reinforcement+learning+using+connection+graph+stability+centrality.+In+Proceedings+of+IEEE+International+Symposium+on+Circuits+and+Systems.+697%2D%2D700.
http://scholar.google.com/scholar?hl=en&q=Usha+Nandini+Raghavan%2C+R%C3%A9ka+Albert%2C+and+Soundar+Kumara.+2007.+Near+linear+time+algorithm+to+detect+community+structures+in+large-scale+networks.+Physical+Review+E+76%2C+3+%282007%29%2C+11.
http://scholar.google.com/scholar?hl=en&q=Shaoqing+Ren%2C+Kaiming+He%2C+Ross+Girshick%2C+and+Jian+Sun.+2015.+Faster+R-CNN%3A+Towards+real-time+object+detection+with+region+proposal+networks.+In+Advances+in+Neural+Information+Processing+Systems+%28NIPS%E2%80%9915%29.+Curran+Associates%2C+91%2D%2D99.+
http://scholar.google.com/scholar?hl=en&q=Jianbo+Shi+and+Jitendra+Malik.+2000.+Normalized+cuts+and+image+segmentation.+IEEE+Transactions+on+Pattern+Analysis+and+Machine+Intelligence+22%2C+8+%28Aug.+2000%29%2C+888%2D%2D905.+10.1109%2F34.868688+
http://scholar.google.com/scholar?hl=en&q=Kimberly+L.+Stachenfeld%2C+Matthew+Botvinick%2C+and+Samuel+J.+Gershman.+2014.+Design+principles+of+the+hippocampal+cognitive+map.+In+Advances+in+Neural+Information+Processing+Systems+%28NIPS%E2%80%9914%29.+Curran+Associates%2C+2528%2D%2D2536.+
http://scholar.google.com/scholar?hl=en&q=Richard+S.+Sutton+and+Andrew+G.+Barto.+1998.+Reinforcement+Learning%3A+An+Introduction.+MIT+Press.+
http://scholar.google.com/scholar?hl=en&q=Richard+S.+Sutton%2C+Doina+Precup%2C+and+Satinder+Singh.+1999.+Between+MDPs+and+semi-MDPs%3A+A+framework+for+temporal+abstraction+in+reinforcement+learning.+Artificial+Intelligence+112+%281999%29%2C+181%2D%2D211.+10.1016%2FS0004-3702%2899%2900052-1+
http://scholar.google.com/scholar?hl=en&q=Christian+Szegedy%2C+Wei+Liu%2C+Yangqing+Jia%2C+Pierre+Sermanet%2C+Scott+Reed%2C+Dragomir+Anguelov%2C+Dumitru+Erhan%2C+Vincent+Vanhoucke%2C+and+Andrew+Rabinovich.+2015.+Going+deeper+with+convolutions.+In+Computer+Vision+and+Pattern+Recognition+%28CVPR%E2%80%9915%29.+1%2D%2D12.
http://scholar.google.com/scholar?hl=en&q=Nasrin+Taghizadeh+and+Hamid+Beigy.+2013.+A+novel+graphical+approach+to+automatic+abstraction+in+reinforcement+learning.+Robotics+and+Autonomous+Systems+61%2C+8+%282013%29%2C+821%2D%2D835.
http://scholar.google.com/scholar?hl=en&q=Alexander+Vezhnevets%2C+Volodymyr+Mnih%2C+Simon+Osindero%2C+Alex+Graves%2C+Oriol+Vinyals%2C+John+Agapiou%2C+and+Koray+Kavukcuoglu.+2016.+Strategic+attentive+writer+for+learning+macro-actions.+In+Advances+in+Neural+Information+Processing+Systems+%28NIPS%E2%80%9916%29%2C+D.+D.+Lee%2C+M.+Sugiyama%2C+U.+V.+Luxburg%2C+I.+Guyon%2C+and+R.+Garnett+%28Eds.%29.+Curran+Associates%2C+3486%2D%2D3494.+
http://scholar.google.com/scholar?hl=en&q=Alexander+Sasha+Vezhnevets%2C+Simon+Osindero%2C+Tom+Schaul%2C+Nicolas+Heess%2C+Max+Jaderberg%2C+David+Silver%2C+and+Koray+Kavukcuoglu.+2017.+FeUdal+networks+for+hierarchical+reinforcement+learning.+In+Proceedings+of+the+International+Conference+on+Machine+Learning+%28ICML%E2%80%9917%29.+1%2D%2D12.
http://scholar.google.com/scholar?hl=en&q=Krista+Rizman+%C5%BDalik.+2008.+An+efficient+K%E2%80%99-Means+clustering+algorithm.+Pattern+Recognition+Letters+29%2C+9+%282008%29%2C+1385%2D%2D1391.+10.1016%2Fj.patrec.2008.02.014+
http://scholar.google.com/scholar?hl=en&q=Christopher+J.+C.+H.+Watkins.+1989.+Learning+from+Delayed+Rewards.+Ph.D.+Dissertation.+King%E2%80%99s+College%2C+Cambridge%2C+UK.
http://scholar.google.com/scholar?hl=en&q=Marcus+Weber%2C+Wasinee+Rungsarityotin%2C+and+Alexander+Schliep.+2004.+Perron+cluster+analysis+and+its+connection+to+graph+partitioning+for+noisy+data.+Technical+Report%2C+Zuse+Institute+Berlin+%28ZIB%29.
http://scholar.google.com/scholar?hl=en&q=Klaus+Wehmuth+and+Artur+Ziviani.+2011.+Distributed+location+of+the+critical+nodes+to+network+robustness+based+on+spectral+analysis.+In+Latin+American+Network+Operations+and+Management+Symposium+%28LANOMS%E2%80%9911%29.+1%2D%2D8.
