http://scholar.google.com/scholar?hl=en&q=Intel+AI.+2017.+Intel+Nervana+Neural+Network+Processors+%28NNP%29+Redefine+AI+Silicon.+Retrieved+from+https%3A%2F%2Fai.intel.com%2Fintel-nervana-neural-network-processors-nnp-redefine-ai-silicon%2F.
http://scholar.google.com/scholar?hl=en&q=Filipp+Akopyan%2C+Jun+Sawada%2C+Andrew+Cassidy%2C+Rodrigo+Alvarez-Icaza%2C+John+Arthur%2C+Paul+Merolla%2C+Nabil+Imam%2C+Yutaka+Nakamura%2C+Pallab+Datta%2C+and+Gi-Joon+Nam.+2015.+TrueNorth%3A+Design+and+tool+flow+of+a+65mW+1+million+neuron+programmable+neurosynaptic+chip.+IEEE+Trans.+Comput.-aided+Design+Integr.+Circ.+Syst.+34%2C+10+%282015%29.
http://scholar.google.com/scholar?hl=en&q=Jorge+Albericio%2C+Alberto+Delm%C3%A1s%2C+Patrick+Judd%2C+Sayeh+Sharify%2C+Gerard+O%E2%80%99Leary%2C+Roman+Genov%2C+and+Andreas+Moshovos.+2017.+Bit-pragmatic+deep+neural+network+computing.+In+Proceedings+of+the+IEEE%2FACM+International+Symposium+on+Microarchitecture.+10.1145%2F3123939.3123982+
http://scholar.google.com/scholar?hl=en&q=Jorge+Albericio%2C+Patrick+Judd%2C+Tayler+Hetherington%2C+Tor+Aamodt%2C+Natalie+E.+Jerger%2C+and+Andreas+Moshovos.+2016.+Cnvlutin%3A+Ineffectual-neuron-free+deep+neural+network+computing.+In+ACM+SIGARCH+Computer+Architecture+News.+10.1109%2FISCA.2016.11+
http://scholar.google.com/scholar?hl=en&q=Hande+Alemdar%2C+Vincent+Leroy%2C+Adrien+Prost-Boucle%2C+and+Fr%C3%A9d%C3%A9ric+P%C3%A9trot.+2017.+Ternary+neural+networks+for+resource-efficient+AI+applications.+In+Proceedings+of+the+International+Joint+Conference+on+Neural+Networks.
http://scholar.google.com/scholar?hl=en&q=Amjad+Almahairi%2C+Nicolas+Ballas%2C+Tim+Cooijmans%2C+Yin+Zheng%2C+Hugo+Larochelle%2C+and+Aaron+Courville.+2016.+Dynamic+capacity+networks.+In+Proceedings+of+the+International+Conference+on+Machine+Learning.+
http://scholar.google.com/scholar?hl=en&q=Amara+Amara%2C+Frederic+Amiel%2C+and+Thomas+Ea.+2006.+FPGA+vs.+ASIC+for+low+power+applications.+Microelectron.+J.+37%2C+8+%282006%29.
http://scholar.google.com/scholar?hl=en&q=Hesham+Amin%2C+K.+Mervyn+Curtis%2C+and+Barrie+R.+Hayes-Gill.+1997.+Piecewise+linear+approximation+applied+to+nonlinear+function+of+a+neural+network.+IEE+Proceedings%E2%80%94Circuits%2C+Devices+and+Systems+144%2C+6+%281997%29.
http://scholar.google.com/scholar?hl=en&q=Renzo+Andri%2C+Lukas+Cavigelli%2C+Davide+Rossi%2C+and+Luca+Benini.+2018.+YodaNN%3A+An+architecture+for+ultra-low+power+binary-weight+CNN+acceleration.+IEEE+Trans.+Comput.-aided+Design+Integr.+Circ.+Syst.+37%2C+1+%282018%29.
http://scholar.google.com/scholar?hl=en&q=Sayed+O.+Ayat%2C+Mohamed+Khalil-Hani%2C+and+Ab+Al-Hadi+Ab+Rahman.+2018.+Optimizing+FPGA-based+CNN+accelerator+for+energy+efficiency+with+an+extended+roofline+model.+Turkish+J.+Electric.+Eng.+Comput.+Sci.+26%2C+2+%282018%29.
http://scholar.google.com/scholar?hl=en&q=Jimmy+Ba+and+Rich+Caruana.+2014.+Do+deep+nets+really+need+to+be+deep%3F+In+Proceedings+of+the+Conference+on+Neural+Information+Processing+Systems.+
http://scholar.google.com/scholar?hl=en&q=Nathan+Bell+and+Michael+Garland.+2009.+Implementing+sparse+matrix-vector+multiplication+on+throughput-oriented+processors.+In+Proceedings+of+the+Conference+on+High+Performance+Computing+Networking%2C+Storage+and+Analysis.+10.1145%2F1654059.1654078+
http://scholar.google.com/scholar?hl=en&q=Emmanuel+Bengio%2C+Pierre-Luc+Bacon%2C+Joelle+Pineau%2C+and+Doina+Precup.+2015.+Conditional+computation+in+neural+networks+for+faster+models.+In+Proceedings+of+the+International+Conference+on+Learning+Representations.
http://scholar.google.com/scholar?hl=en&q=Yoshua+Bengio%2C+Nicholas+L%C3%A9onard%2C+and+Aaron+Courville.+2013.+Estimating+or+propagating+gradients+through+stochastic+neurons+for+conditional+computation.+arXiv+preprint+arXiv%3A1308.3432+%282013%29.
http://scholar.google.com/scholar?hl=en&q=Andrew+Boutros%2C+Sadegh+Yazdanshenas%2C+and+Vaughn+Betz.+2018.+Embracing+diversity%3A+Enhanced+DSP+blocks+for+low-precision+deep+learning+on+FPGAs.+In+Proceedings+of+the+International+Conference+on+Field-programmable+Logic+and+Applications.
http://scholar.google.com/scholar?hl=en&q=Zhaowei+Cai%2C+Xiaodong+He%2C+Jian+Sun%2C+and+Nuno+Vasconcelos.+2017.+Deep+learning+with+low+precision+by+half-wave+Gaussian+quantization.+In+Proceedings+of+the+IEEE+Conference+on+Computer+Vision+and+Pattern+Recognition.
http://scholar.google.com/scholar?hl=en&q=Adrian+Caulfield%2C+Eric+Chung%2C+Andrew+Putnam%2C+Hari+Angepat%2C+Jeremy+Fowers%2C+Michael+Haselman%2C+Stephen+Heil%2C+Matt+Humphrey%2C+Puneet+Kaur%2C+Joo-Young+Kim%2C+Daniel+Lo%2C+Todd+Massengill%2C+Kalin+Ovtcharov%2C+Michael+Papamichael%2C+Lisa+Woods%2C+Sitaram+Lanka%2C+Derek+Chiou%2C+and+Doug+Burger.+2016.+A+cloud-scale+acceleration+architecture.+In+Proceedings+of+the+IEEE%2FACM+International+Symposium+on+Microarchitecture.+
http://scholar.google.com/scholar?hl=en&q=Andre+X.+M.+Chang+and+Eugenio+Culurciello.+2017.+Hardware+accelerators+for+recurrent+neural+networks+on+FPGA.+In+Proceedings+of+the+International+Symposium+on+Circuits+and+Systems.
http://scholar.google.com/scholar?hl=en&q=Chenyi+Chen%2C+Ari+Seff%2C+Alain+Kornhauser%2C+and+Jianxiong+Xiao.+2015.+Deepdriving%3A+Learning+affordance+for+direct+perception+in+autonomous+driving.+In+Proceedings+of+the+IEEE+International+Conference+on+Computer+Vision.+10.1109%2FICCV.2015.312+
http://scholar.google.com/scholar?hl=en&q=Guobin+Chen%2C+Wongun+Choi%2C+Xiang+Yu%2C+Tony+Han%2C+and+Manmohan+Chandraker.+2017.+Learning+efficient+object+detection+models+with+knowledge+distillation.+In+Proceedings+of+the+Conference+on+Neural+Information+Processing+Systems.+
http://scholar.google.com/scholar?hl=en&q=Wenlin+Chen%2C+James+Wilson%2C+Stephen+Tyree%2C+Kilian+Weinberger%2C+and+Yixin+Chen.+2015.+Compressing+neural+networks+with+the+hashing+trick.+In+Proceedings+of+the+International+Conference+on+Machine+Learning.+
http://scholar.google.com/scholar?hl=en&q=Yunji+Chen%2C+Tao+Luo%2C+Shaoli+Liu%2C+Shijin+Zhang%2C+Liqiang+He%2C+Jia+Wang%2C+Ling+Li%2C+Tianshi+Chen%2C+Zhiwei+Xu%2C+and+Ninghui+Sun.+2014.+DaDianNao%3A+A+machine-learning+supercomputer.+In+Proceedings+of+the+IEEE%2FACM+International+Symposium+on+Microarchitecture.+10.1109%2FMICRO.2014.58+
http://scholar.google.com/scholar?hl=en&q=Yu-Hsin+Chen%2C+Tushar+Krishna%2C+Joel+S.+Emer%2C+and+Vivienne+Sze.+2017.+Eyeriss%3A+An+energy-efficient+reconfigurable+accelerator+for+deep+convolutional+neural+networks.+IEEE+Journal+of+Solid-state+Circuits+52%2C+1+%282017%29.
http://scholar.google.com/scholar?hl=en&q=Jian+Cheng%2C+Peisong+Wang%2C+Gang+Li%2C+Qinghao+Hu%2C+and+Hanqing+Lu.+2018.+Recent+advances+in+efficient+computation+of+deep+convolutional+neural+networks.+Front.+Info.+Technol.+Electron.+Eng.+19%2C+1+%282018%29.
http://scholar.google.com/scholar?hl=en&q=Yu+Cheng%2C+Duo+Wang%2C+Pan+Zhou%2C+and+Tao+Zhang.+2018.+Model+compression+and+acceleration+for+deep+neural+networks%3A+The+principles%2C+progress%2C+and+challenges.+IEEE+Signal+Process.+Mag.+35%2C+1+%282018%29.
http://scholar.google.com/scholar?hl=en&q=Yu+Cheng%2C+Felix+X.+Yu%2C+Rogerio+S.+Feris%2C+Sanjiv+Kumar%2C+Alok+Choudhary%2C+and+Shi-Fu+Chang.+2015.+An+exploration+of+parameter+redundancy+in+deep+networks+with+circulant+projections.+In+Proceedings+of+the+International+Conference+on+Computer+Vision.+10.1109%2FICCV.2015.327+
http://scholar.google.com/scholar?hl=en&q=Yu+Cheng%2C+Felix+X.+Yu%2C+Rogerio+S.+Feris%2C+Sanjiv+Kumar%2C+Alok+Choudhary%2C+and+Shih-Fu+Chang.+2015.+Fast+neural+networks+with+circulant+projections.+arXiv+preprint+arXiv%3A1502.03436+%282015%29.
http://scholar.google.com/scholar?hl=en&q=Eric+Chung%2C+Jeremy+Fowers%2C+Kalin+Ovtcharov%2C+Michael+Papamichael%2C+Adrian+Caulfield%2C+Todd+Massengil%2C+Ming+Liu%2C+Daniel+Lo%2C+Shlomi+Alkalay%2C+Michael+Haselman%2C+Christian+Boehn%2C+Oren+Firestein%2C+Alessandro+Forin%2C+Kang+S.+Gatlin%2C+Mahdi+Ghandi%2C+Stephen+Heil%2C+Kyle+Holohan%2C+Tamas+Juhasz%2C+Ratna+K.+Kovvuri%2C+Sitaram+Lanka%2C+Friedel+van+Megen%2C+Dima+Mukhortov%2C+Prerak+Patel%2C+Steve+Reinhardt%2C+Adam+Sapek%2C+Raja+Seera%2C+Balaji+Sridharan%2C+Lisa+Woods%2C+Phillip+Yi-Xiao%2C+Ritchie+Zhao%2C+and+Doug+Burger.+2017.+Accelerating+persistent+neural+networks+at+datacenter+scale.+In+Proceedings+of+the+Conference+on+Hot+Chips.
http://scholar.google.com/scholar?hl=en&q=Philip+Colangelo%2C+Nasibeh+Nasiri%2C+Eriko+Nurvitadhi%2C+Asit+Mishra%2C+Martin+Margala%2C+and+Kevin+Nealis.+2018.+Exploration+of+low+numerical+precision+deep+learning+inference+using+Intel+FPGAs.+In+Proceedings+of+the+International+Symposium+on+Field-programmable+Custom+Computing+Machines.+10.1145%2F3174243.3174999+
http://scholar.google.com/scholar?hl=en&q=Matthieu+Courbariaux+and+Yoshua+Bengio.+2016.+BinaryNet%3A+Training+deep+neural+networks+with+weights+and+activations+constrained+to+%2B1+or+.+arXiv+preprint+arXiv%3A1602.02830+%282016%29.
http://scholar.google.com/scholar?hl=en&q=Matthieu+Courbariaux%2C+Yoshua+Bengio%2C+and+Jean-Pierre+David.+2015.+BinaryConnect%3A+Training+deep+neural+networks+with+binary+weights+during+propagations.+In+Conference+on+Neural+Information+Processing+Systems.+
http://scholar.google.com/scholar?hl=en&q=Matthieu+Courbariaux%2C+Jean-Pierre+David%2C+and+Yoshua+Bengio.+2015.+Low+precision+storage+for+deep+learning.+In+International+Conference+on+Learning+Representations.
http://scholar.google.com/scholar?hl=en&q=Vin+De+Silva+and+Lek-Heng+Lim.+2006.+Tensor+rank+and+the+ill-posedness+of+the+best+low-rank+approximation+problem.+SIAM+J.+Matrix+Anal.+Appl.+30%2C+3+%282006%29.+
http://scholar.google.com/scholar?hl=en&q=Wei+Deng%2C+Wotao+Yin%2C+and+Yin+Zhang.+2013.+Group+sparse+optimization+by+alternating+direction+method.+In+Proceedings+of+the+International+Society+for+Optical+Engineering.
http://scholar.google.com/scholar?hl=en&q=Misha+Denil%2C+Babak+Shakibi%2C+Laurent+Dinh%2C+and+Nando+De+Freitas.+2013.+Predicting+parameters+in+deep+learning.+In+Proceedings+of+the+Conference+on+Neural+Information+Processing+Systems.+
http://scholar.google.com/scholar?hl=en&q=Emily+L.+Denton%2C+Wojciech+Zaremba%2C+Joan+Bruna%2C+Yann+LeCun%2C+and+Rob+Fergus.+2014.+Exploiting+linear+structure+within+convolutional+networks+for+efficient+evaluation.+In+Proceedings+of+the+Conference+on+Neural+Information+Processing+Systems.+
http://scholar.google.com/scholar?hl=en&q=Caiwen+Ding%2C+Siyu+Liao%2C+Yanzhi+Wang%2C+Zhe+Li%2C+Ning+Liu%2C+Youwei+Zhuo%2C+Chao+Wang%2C+Xuehai+Qian%2C+Yu+Bai%2C+and+Geng+Yuan.+2017.+CirCNN%3A+Accelerating+and+compressing+deep+neural+networks+using+block-circulant+weight+matrices.+In+Proceedings+of+the+IEEE%2FACM+International+Symposium+on+Microarchitecture.+10.1145%2F3123939.3124552+
http://scholar.google.com/scholar?hl=en&q=Caiwen+Ding%2C+Ao+Ren%2C+Geng+Yuan%2C+Xiaolong+Ma%2C+Jiayu+Li%2C+Ning+Liu%2C+Bo+Yuan%2C+and+Yanzhi+Wang.+2018.+Structured+weight+matrices-based+hardware+accelerators+in+deep+neural+networks%3A+FPGAs+and+ASICs.+arXiv+preprint+arXiv%3A1804.11239+%282018%29.+10.1145%2F3194554.3194625+
http://scholar.google.com/scholar?hl=en&q=Wlodzislaw+Duch+and+Norbert+Jankowski.+1999.+Survey+of+neural+transfer+functions.+Neural+Comput.+Surveys+2%2C+1+%281999%29.
http://scholar.google.com/scholar?hl=en&q=Cl%C3%A9ment+Farabet%2C+Berin+Martini%2C+Benoit+Corda%2C+Polina+Akselrod%2C+Eugenio+Culurciello%2C+and+Yann+LeCun.+2011.+NeuFlow%3A+A+runtime+reconfigurable+dataflow+processor+for+vision.+In+Proceedings+of+the+IEEE+Computer+Society+Computer+Vision+and+Pattern+Recognition+Workshops.
http://scholar.google.com/scholar?hl=en&q=Sean+Fox%2C+David+Boland%2C+and+Philip+H.+W.+Leong.+2018.+FPGA+FastFood+%2D%2D+A+high+speed+systolic+implementation+of+a+large+scale+online+kernel+method.+In+Proceedings+of+the+ACM%2FSIGDA+International+Symposium+on+Field-programmable+Gate+Arrays.+10.1145%2F3174243.3174271+
http://scholar.google.com/scholar?hl=en&q=Dhiraj+Gandhi%2C+Lerrel+Pinto%2C+and+Abhinav+Gupta.+2017.+Learning+to+fly+by+crashing.+In+Proceedings+of+the+IEEE%2FRSJ+International+Conference+on+Intelligent+Robots+and+Systems.
http://scholar.google.com/scholar?hl=en&q=Chang+Gao%2C+Daniel+Neil%2C+Enea+Ceolini%2C+Shih-Chii+Liu%2C+and+Tobi+Delbruck.+2018.+DeltaRNN%3A+A+power-efficient+recurrent+neural+network+accelerator.+In+Proceedings+of+the+ACM%2FSIGDA+International+Symposium+on+Field-programmable+Gate+Arrays.+10.1145%2F3174243.3174261+
http://scholar.google.com/scholar?hl=en&q=Mohammad+Ghasemzadeh%2C+Mohammad+Samragh%2C+and+Farinaz+Koushanfar.+2018.+ReBNet%3A+Residual+binarized+neural+network.+In+Proceedings+of+the+IEEE+International+Symposium+on+Field-programmable+Custom+Computing+Machines.
http://scholar.google.com/scholar?hl=en&q=Robert+M.+Gray.+2006.+Toeplitz+and+circulant+matrices%3A+A+review.+Found.+Trends+Commun.+Info.+Theory+2%2C+3+%282006%29.+10.1561%2F0100000006+
http://scholar.google.com/scholar?hl=en&q=Yijin+Guan%2C+Zhihang+Yuan%2C+Guangyu+Sun%2C+and+Jason+Cong.+2017.+FPGA-based+accelerator+for+long+short-term+memory+recurrent+neural+networks.+In+Proceedings+of+the+Asia+and+South+Pacific+Design+Automation+Conference.
http://scholar.google.com/scholar?hl=en&q=Denis+A.+Gudovskiy+and+Luca+Rigazio.+2017.+ShiftCNN%3A+Generalized+low-precision+architecture+for+inference+of+convolutional+neural+networks.+arXiv+preprint+arXiv%3A1706.02393+%282017%29.
http://scholar.google.com/scholar?hl=en&q=Kaiyuan+Guo%2C+Lingzhi+Sui%2C+Jiantao+Qiu%2C+Song+Yao%2C+Song+Han%2C+Yu+Wang%2C+and+Huazhong+Yang.+2016.+Angel-Eye%3A+A+complete+design+flow+for+mapping+CNN+onto+customized+hardware.+In+Proceedings+of+the+IEEE+Computer+Society+Annual+Symposium+on+VLSI.
http://scholar.google.com/scholar?hl=en&q=Kaiyuan+Guo%2C+Shulin+Zeng%2C+Jincheng+Yu%2C+Yu+Wang%2C+and+Huazhong+Yang.+2017.+A+survey+of+FPGA+based+neural+network+accelerator.+ACM+Trans.+Reconfig.+Technol.+Syst.+9%2C+4+%282017%29.+10.1145%2F3289185+
http://scholar.google.com/scholar?hl=en&q=Yiwen+Guo%2C+Anbang+Yao%2C+and+Yurong+Chen.+2016.+Dynamic+network+surgery+for+efficient+DNNs.+In+Proceedings+of+the+Conference+on+Neural+Information+Processing+Systems.+
http://scholar.google.com/scholar?hl=en&q=Suyog+Gupta%2C+Ankur+Agrawal%2C+Kailash+Gopalakrishnan%2C+and+Pritish+Narayanan.+2015.+Deep+learning+with+limited+numerical+precision.+In+Proceedings+of+the+International+Conference+on+Machine+Learning.+
http://scholar.google.com/scholar?hl=en&q=Song+Han%2C+Junlong+Kang%2C+Huizi+Mao%2C+Yiming+Hu%2C+Xin+Li%2C+Yubin+Li%2C+Dongliang+Xie%2C+Hong+Luo%2C+Song+Yao%2C+and+Yu+Wang.+2017.+ESE%3A+Efficient+speech+recognition+engine+with+sparse+LSTM+on+FPGA.+In+Proceedings+of+the+ACM%2FSIGDA+International+Symposium+on+Field-programmable+Gate+Arrays.+10.1145%2F3020078.3021745+
http://scholar.google.com/scholar?hl=en&q=Song+Han%2C+Xingyu+Liu%2C+Huizi+Mao%2C+Jing+Pu%2C+Ardavan+Pedram%2C+Mark+A.+Horowitz%2C+and+William+J.+Dally.+2016.+EIE%3A+Efficient+inference+engine+on+compressed+deep+neural+network.+In+Proceedings+of+the+ACM%2FIEEE+International+Symposium+on+Computer+Architecture.+10.1109%2FISCA.2016.30+
http://scholar.google.com/scholar?hl=en&q=Song+Han%2C+Huizi+Mao%2C+and+William+J.+Dally.+2016.+Deep+compression%3A+Compressing+deep+neural+networks+with+pruning%2C+trained+quantization+and+Huffman+coding.+In+Proceedings+of+the+International+Conference+on+Learning+Representations.
http://scholar.google.com/scholar?hl=en&q=Song+Han%2C+Jeff+Pool%2C+John+Tran%2C+and+William+J.+Dally.+2015.+Learning+both+weights+and+connections+for+efficient+neural+network.+In+Proceedings+of+the+Conference+on+Neural+Information+Processing+Systems.+
http://scholar.google.com/scholar?hl=en&q=Babak+Hassibi+and+David+G.+Stork.+1993.+Second+order+derivatives+for+network+pruning%3A+Optimal+brain+surgeon.+In+Proceedings+of+the+Conference+on+Neural+Information+Processing+Systems.+
http://scholar.google.com/scholar?hl=en&q=Yihui+He%2C+Xiangyu+Zhang%2C+and+Jian+Sun.+2017.+Channel+pruning+for+accelerating+very+deep+neural+networks.+In+Proceedings+of+the+International+Conference+on+Computer+Vision.
http://scholar.google.com/scholar?hl=en&q=Gopalakrishna+Hegde+and+Nachiket+Kapre.+2018.+CaffePresso%3A+Accelerating+convolutional+networks+on+embedded+SoCs.+ACM+Trans.+Embed.+Comput.+Syst.+17%2C+1+%282018%29.+10.1145%2F3105925+
http://scholar.google.com/scholar?hl=en&q=Geoffrey+Hinton%2C+Oriol+Vinyals%2C+and+Jeff+Dean.+2015.+Distilling+the+knowledge+in+a+neural+network.+arXiv+preprint+arXiv%3A1503.02531+%282015%29.
http://scholar.google.com/scholar?hl=en&q=Andrew+G.+Howard%2C+Menglong+Zhu%2C+Bo+Chen%2C+Dmitry+Kalenichenko%2C+Weijun+Wang%2C+Tobias+Weyand%2C+Marco+Andreetto%2C+and+Hartwig+Adam.+2017.+MobileNets%3A+Efficient+convolutional+neural+networks+for+mobile+vision+applications.+arXiv+preprint+arXiv%3A1704.04861+%282017%29.
http://scholar.google.com/scholar?hl=en&q=Intel.+2018.+Intel+at+Hot+Chips+2018%3A+Showing+the+Ankle+of+Cascade+Lake.+Retrieved+from+https%3A%2F%2Fwww.anandtech.com%2Fshow%2F13239%2Fintel-at-hot-chips-2018-showing-the-ankle-of-cascade-lake.
http://scholar.google.com/scholar?hl=en&q=Benoit+Jacob%2C+Skirmantas+Kligys%2C+Bo+Chen%2C+Menglong+Zhu%2C+Matthew+Tang%2C+Andrew+Howard%2C+Hartwig+Adam%2C+and+Dmitry+Kalenichenko.+2017.+Quantization+and+training+of+neural+networks+for+efficient+integer-arithmetic-only+inference.+arXiv+preprint+arXiv%3A1712.05877+%282017%29.
http://scholar.google.com/scholar?hl=en&q=Max+Jaderberg%2C+Andrea+Vedaldi%2C+and+Andrew+Zisserman.+2014.+Speeding+up+convolutional+neural+networks+with+low+rank+expansions.+In+Proceedings+of+the+British+Machine+Vision+Conference.
http://scholar.google.com/scholar?hl=en&q=Herve+Jegou%2C+Matthijs+Douze%2C+and+Cordelia+Schmid.+2011.+Product+quantization+for+nearest+neighbor+search.+IEEE+Trans.+Pattern+Anal.+Mach.+Intell.+33%2C+1+%282011%29.+10.1109%2FTPAMI.2010.57+
http://scholar.google.com/scholar?hl=en&q=Norman+P.+Jouppi%2C+Cliff+Young%2C+Nishant+Patil%2C+and+David+Patterson.+2018.+A+domain-specific+architecture+for+deep+neural+networks.+Commun.+ACM+61%2C+9+%282018%29.+10.1145%2F3154484+
http://scholar.google.com/scholar?hl=en&q=Norman+P.+Jouppi%2C+Cliff+Young%2C+Nishant+Patil%2C+David+Patterson%2C+Gaurav+Agrawal%2C+Raminder+Bajwa%2C+Sarah+Bates%2C+Suresh+Bhatia%2C+Nan+Boden%2C+and+Al+Borchers.+2017.+In-datacenter+performance+analysis+of+a+Tensor+Processing+Unit.+In+Proceedings+of+the+International+Symposium+on+Computer+Architecture.+10.1145%2F3079856.3080246+
http://scholar.google.com/scholar?hl=en&q=Patrick+Judd%2C+Jorge+Albericio%2C+Tayler+Hetherington%2C+Tor+M.+Aamodt%2C+and+Andreas+Moshovos.+2016.+Stripes%3A+Bit-serial+deep+neural+network+computing.+In+Proceedings+of+the+IEEE%2FACM+International+Symposium+on+Microarchitecture.+
http://scholar.google.com/scholar?hl=en&q=Andrej+Karpathy%2C+George+Toderici%2C+Sanketh+Shetty%2C+Thomas+Leung%2C+Rahul+Sukthankar%2C+and+Li+Fei-Fei.+2014.+Large-scale+video+classification+with+convolutional+neural+networks.+In+International+Conference+on+Computer+Vision.+10.1109%2FCVPR.2014.223+
http://scholar.google.com/scholar?hl=en&q=Soroosh+Khoram+and+Jing+Li.+2018.+Adaptive+quantization+of+neural+networks.+In+Proceedings+of+the+International+Conference+on+Learning+Representations.
http://scholar.google.com/scholar?hl=en&q=Urs+K%C3%B6ster%2C+Tristan+Webb%2C+Xin+Wang%2C+Marcel+Nassar%2C+Arjun+K.+Bansal%2C+William+Constable%2C+Oguz+Elibol%2C+Scott+Gray%2C+Stewart+Hall%2C+Luke+Hornof%2C+Amir+Khosrowshahi%2C+Kloss+Carey%2C+Ruby+J.+Pai%2C+and+Naveen+Rao.+2017.+Flexpoint%3A+An+adaptive+numerical+format+for+efficient+training+of+deep+neural+networks.+In+Proceedings+of+the+Conference+on+Neural+Information+Processing+Systems.+
http://scholar.google.com/scholar?hl=en&q=Alexandros+Kouris%2C+Stylianos+I.+Venieris%2C+and+Christos-Savvas+Bouganis.+2018.+CascadeCNN%3A+Pushing+the+performance+limits+of+quantisation+in+convolutional+neural+networks.+In+Proceedings+of+the+International+Conference+on+Field-programmable+Logic+and+Applications.
http://scholar.google.com/scholar?hl=en&q=Liangzhen+Lai%2C+Naveen+Suda%2C+and+Vikas+Chandra.+2017.+Deep+convolutional+neural+network+inference+with+floating-point+weights+and+fixed-point+activations.+In+Proceedings+of+the+International+Conference+on+Machine+Learning.
http://scholar.google.com/scholar?hl=en&q=Vadim+Lebedev%2C+Yaroslav+Ganin%2C+Maksim+Rakhuba%2C+Ivan+Oseledets%2C+and+Victor+Lempitsky.+2015.+Speeding-up+convolutional+neural+networks+using+fine-tuned+CP-decomposition.+In+Proceedings+of+the+International+Conference+on+Learning+Representations.
http://scholar.google.com/scholar?hl=en&q=Vadim+Lebedev+and+Victor+Lempitsky.+2016.+Fast+convnets+using+group-wise+brain+damage.+In+Proceedings+of+the+IEEE+Conference+on+Computer+Vision+and+Pattern+Recognition.
http://scholar.google.com/scholar?hl=en&q=Yann+LeCun%2C+John+S.+Denker%2C+and+Sara+A.+Solla.+1990.+Optimal+Brain+Damage.+In+Proceedings+of+the+Conference+on+Neural+Information+Processing+Systems.+
http://scholar.google.com/scholar?hl=en&q=Edward+H.+Lee%2C+Daisuke+Miyashita%2C+Elaina+Chai%2C+Boris+Murmann%2C+and+Simon+S.+Wong.+2017.+LogNet%3A+Energy-efficient+neural+networks+using+logarithmic+computation.+In+Proceedings+of+the+IEEE+International+Conference+on+Acoustics%2C+Speech+and+Signal+Processing.
http://scholar.google.com/scholar?hl=en&q=Bing+Li%2C+Wei+Wen%2C+Jiachen+Mao%2C+Sicheng+Li%2C+Yiran+Chen%2C+and+Hai+Li.+2018.+Running+sparse+and+low-precision+neural+network%3A+When+algorithm+meets+hardware.+In+Proceedings+of+the+Asia+and+South+Pacific+Design+Automation+Conference.+
http://scholar.google.com/scholar?hl=en&q=Fengfu+Li+and+Bin+Liu.+2016.+Ternary+weight+networks.+In+Proceedings+of+the+Conference+on+Neural+Information+Processing+Systems.
http://scholar.google.com/scholar?hl=en&q=Hao+Li%2C+Soham+De%2C+Zheng+Xu%2C+Christoph+Studer%2C+Hanan+Samet%2C+and+Tom+Goldstein.+2017.+Training+quantized+nets%3A+A+deeper+understanding.+In+Proceedings+of+the+Conference+on+Neural+Information+Processing+Systems.+
http://scholar.google.com/scholar?hl=en&q=Hao+Li%2C+Asim+Kadav%2C+Igor+Durdanovic%2C+Hanan+Samet%2C+and+Hans+P.+Graf.+2017.+Pruning+filters+for+efficient+convnets.+In+Proceedings+of+the+International+Conference+on+Learning+Representations.
http://scholar.google.com/scholar?hl=en&q=Sicheng+Li%2C+Wei+Wen%2C+Yu+Wang%2C+Song+Han%2C+Yiran+Chen%2C+and+Hai+Li.+2017.+An+FPGA+design+framework+for+CNN+sparsification+and+acceleration.+In+Proceedings+of+the+IEEE+International+Symposium+on+Field-programmable+Custom+Computing+Machines.
http://scholar.google.com/scholar?hl=en&q=Sicheng+Li%2C+Chunpeng+Wu%2C+Hai+Li%2C+Boxun+Li%2C+Yu+Wang%2C+and+Qinru+Qiu.+2015.+FPGA+acceleration+of+recurrent+neural+network+based+language+model.+In+Proceedings+of+the+IEEE+International+Symposium+on+Field-programmable+Custom+Computing+Machines.+10.1109%2FFCCM.2015.50+
http://scholar.google.com/scholar?hl=en&q=Shuang+Liang%2C+Shouyi+Yin%2C+Leibo+Liu%2C+Wayne+Luk%2C+and+Shaojun+Wei.+2018.+FP-BNN%3A+Binarized+neural+network+on+FPGA.+Neurocomputing+275%2C+C+%282018%29.
http://scholar.google.com/scholar?hl=en&q=Darryl+Lin%2C+Sachin+Talathi%2C+and+Sreekanth+Annapureddy.+2016.+Fixed+point+quantization+of+deep+convolutional+networks.+In+Proceedings+of+the+International+Conference+on+Machine+Learning.+
http://scholar.google.com/scholar?hl=en&q=Ji+Lin%2C+Yongming+Rao%2C+Jiwen+Lu%2C+and+Jie+Zhou.+2017.+Runtime+neural+pruning.+In+Proceedings+of+the+Conference+on+Neural+Information+Processing+Systems.+
http://scholar.google.com/scholar?hl=en&q=Xiaofan+Lin%2C+Cong+Zhao%2C+and+Wei+Pan.+2017.+Towards+accurate+binary+convolutional+neural+network.+In+Proceedings+of+the+Conference+on+Neural+Information+Processing+Systems.+
http://scholar.google.com/scholar?hl=en&q=Zhouhan+Lin%2C+Matthieu+Courbariaux%2C+Roland+Memisevic%2C+and+Yoshua+Bengio.+2015.+Neural+networks+with+few+multiplications.+In+Proceedings+of+the+International+Conference+on+Learning+Representations.
http://scholar.google.com/scholar?hl=en&q=Ji+Liu%2C+Przemyslaw+Musialski%2C+Peter+Wonka%2C+and+Jieping+Ye.+2013.+Tensor+completion+for+estimating+missing+values+in+visual+data.+IEEE+Trans.+Pattern+Anal.+Mach.+Intell.+35%2C+1+%282013%29.+10.1109%2FTPAMI.2012.39+
http://scholar.google.com/scholar?hl=en&q=Lanlan+Liu+and+Jia+Deng.+2017.+Dynamic+deep+neural+networks%3A+Optimizing+accuracy-efficiency+trade-offs+by+selective+execution.+arXiv+preprint+arXiv%3A1701.00299+%282017%29.
http://scholar.google.com/scholar?hl=en&q=Wei+Liu%2C+Dragomir+Anguelov%2C+Dumitru+Erhan%2C+Christian+Szegedy%2C+Scott+Reed%2C+Cheng-Yang+Fu%2C+and+Alexander+C.+Berg.+2016.+SSD%3A+Single+shot+multibox+detector.+In+Proceedings+of+the+European+Conference+on+Computer+Vision.
http://scholar.google.com/scholar?hl=en&q=Xuan+Liu%2C+Di+Cao%2C+and+Kai+Yu.+2018.+Binarized+LSTM+language+model.+In+Proceedings+of+the+Conference+of+the+North+American+Chapter+of+the+Association+for+Computational+Linguistics.
http://scholar.google.com/scholar?hl=en&q=Zhuang+Liu%2C+Jianguo+Li%2C+Zhiqiang+Shen%2C+Gao+Huang%2C+Shoumeng+Yan%2C+and+Changshui+Zhang.+2017.+Learning+efficient+convolutional+networks+through+network+slimming.+In+Proceedings+of+the+International+Conference+on+Computer+Vision.
http://scholar.google.com/scholar?hl=en&q=Zhiyun+Lu%2C+Vikas+Sindhwani%2C+and+Tara+N.+Sainath.+2016.+Learning+compact+recurrent+neural+networks.+In+Proceedings+of+the+IEEE+International+Conference+on+Acoustics%2C+Speech+and+Signal+Processing.
http://scholar.google.com/scholar?hl=en&q=Yufei+Ma%2C+Yu+Cao%2C+Sarma+Vrudhula%2C+and+Jae-Sun+Seo.+2017.+Optimizing+loop+operation+and+dataflow+in+FPGA+acceleration+of+deep+convolutional+neural+networks.+In+Proceedings+of+the+ACM%2FSIGDA+International+Symposium+on+Field-programmable+Gate+Arrays.+10.1145%2F3020078.3021736+
http://scholar.google.com/scholar?hl=en&q=Naveen+Mellempudi%2C+Abhisek+Kundu%2C+Dheevatsa+Mudigere%2C+Dipankar+Das%2C+Bharat+Kaul%2C+and+Pradeep+Dubey.+2017.+Ternary+neural+networks+with+fine-grained+quantization.+arXiv+preprint+arXiv%3A1705.01462+%282017%29.
http://scholar.google.com/scholar?hl=en&q=Asit+Mishra%2C+Eriko+Nurvitadhi%2C+Jeffrey+J.+Cook%2C+and+Debbie+Marr.+2018.+WRPN%3A+Wide+reduced-precision+networks.+In+Proceedings+of+the+International+Conference+on+Learning+Representations.
http://scholar.google.com/scholar?hl=en&q=Pavlo+Molchanov%2C+Stephen+Tyree%2C+Tero+Karras%2C+Timo+Aila%2C+and+Jan+Kautz.+2017.+Pruning+convolutional+neural+networks+for+resource+efficient+inference.+In+Proceedings+of+the+International+Conference+on+Learning+Representations.
http://scholar.google.com/scholar?hl=en&q=Alexander+Monakov%2C+Anton+Lokhmotov%2C+and+Arutyun+Avetisyan.+2010.+Automatically+tuning+sparse+matrix-vector+multiplication+for+GPU+architectures.+In+Proceedings+of+the+International+Conference+on+High-performance+Embedded+Architectures+and+Compilers.+10.1007%2F978-3-642-11515-8_10+
http://scholar.google.com/scholar?hl=en&q=Bert+Moons+and+Marian+Verhelst.+2016.+A+0.3%2D%2D2.6+TOPS%2FW+precision-scalable+processor+for+real-time+large-scale+convnets.+In+Proceedings+of+the+IEEE+Symposium+on+VLSI+Circuits.
http://scholar.google.com/scholar?hl=en&q=Duncan+Moss%2C+Srivatsan+Krishnan%2C+Eriko+Nurvitadhi%2C+Piotr+Ratuszniak%2C+Chris+Johnson%2C+Jaewoong+Sim%2C+Asit+Mishra%2C+Debbie+Marr%2C+Suchit+Subhaschandra%2C+and+Philip+H.+W.+Leong.+2018.+A+customizable+matrix+multiplication+framework+for+the+Intel+HARPv2+Xeon+%2B+FPGA+platform.+In+Proceedings+of+the+ACM%2FSIGDA+International+Symposium+on+Field-programmable+Gate+Arrays.+10.1145%2F3174243.3174258+
http://scholar.google.com/scholar?hl=en&q=Arvind+Neelakantan%2C+Luke+Vilnis%2C+Quoc+V.+Le%2C+Ilya+Sutskever%2C+Lukasz+Kaiser%2C+Karol+Kurach%2C+and+James+Martens.+2015.+Adding+gradient+noise+improves+learning+for+very+deep+networks.+In+Proceedings+of+the+International+Conference+on+Learning+Representations.
http://scholar.google.com/scholar?hl=en&q=Steven+J.+Nowlan+and+Geoffrey+E.+Hinton.+1992.+Simplifying+neural+networks+by+soft+weight-sharing.+Neural+Comput.+4%2C+4+%281992%29.+10.1162%2Fneco.1992.4.4.473+
http://scholar.google.com/scholar?hl=en&q=Eriko+Nurvitadhi%2C+Jeff+Cook%2C+Asit+Mishra%2C+Debbie+Marr%2C+Kevin+Nealis%2C+Philip+Colangelo%2C+Andrew+Ling%2C+Davor+Capalija%2C+Utku+Aydonat%2C+Sergey+Shumarayev%2C+and+Aravind+Dasu.+2018.+In-package+domain-specific+ASICs+for+Intel+Stratix+10+FPGAs%3A+A+case+study+of+accelerating+deep+learning+using+TensorTile+ASIC.+In+Proceedings+of+the+International+Conference+on+Field-programmable+Logic+and+Applications.+10.1145%2F3174243.3174966+
http://scholar.google.com/scholar?hl=en&q=Eriko+Nurvitadhi%2C+Ganesh+Venkatesh%2C+Jaewoong+Sim%2C+Debbie+Marr%2C+Randy+Huang%2C+Jason+O.+G.+Hock%2C+Yeong+T.+Liew%2C+Krishnan+Srivatsan%2C+Duncan+Moss%2C+and+Suchit+Subhaschandra.+2017.+Can+FPGAs+beat+GPUs+in+accelerating+next-generation+deep+neural+networks%3F+In+Proceedings+of+the+ACM%2FSIGDA+International+Symposium+on+Field-programmable+Gate+Arrays.+10.1145%2F3020078.3021740+
http://scholar.google.com/scholar?hl=en&q=Nvidia.+2018.+CUDA+C+Programming+Guide.+Retrieved+from+https%3A%2F%2Fdocs.nvidia.com%2Fcuda%2Fcuda-c-programming-guide%2Findex.html%23arithmetic-instructions.
http://scholar.google.com/scholar?hl=en&q=Nvidia.+2018.+NVIDIA+Turing+Architecture+Whitepaper.+Retrieved+from+https%3A%2F%2Fwww.nvidia.com%2Fcontent%2Fdam%2Fen-zz%2FSolutions%2Fdesign-visualization%2Ftechnologies%2Fturing-architecture%2FNVIDIA-Turing-Architecture-Whitepaper.pdf.
http://scholar.google.com/scholar?hl=en&q=Georg+Ofenbeck%2C+Ruedi+Steinmann%2C+Victoria+Caparros%2C+Daniele+G.+Spampinato%2C+and+Markus+Puschel.+2014.+Applying+the+roofline+model.+In+Proceedings+of+the+IEEE+International+Symposium+on+Performance+Analysis+of+Systems+and+Software.
http://scholar.google.com/scholar?hl=en&q=Joachim+Ott%2C+Zhouhan+Lin%2C+Ying+Zhang%2C+Shih-Chii+Liu%2C+and+Yoshua+Bengio.+2016.+Recurrent+neural+networks+with+limited+numerical+precision.+arXiv+preprint+arXiv%3A1608.06902+%282016%29.
http://scholar.google.com/scholar?hl=en&q=Thorbj%C3%B6rn+Posewsky+and+Daniel+Ziener.+2018.+Throughput+optimizations+for+FPGA-based+deep+neural+network+inference.+Microprocess.+Microsyst.+60+%282018%29.
http://scholar.google.com/scholar?hl=en&q=Adrien+Prost-Boucle%2C+Alban+Bourge%2C+Fr%C3%A9d%C3%A9ric+P%C3%A9trot%2C+Hande+Alemdar%2C+Nicholas+Caldwell%2C+and+Vincent+Leroy.+2017.+Scalable+high-performance+architecture+for+convolutional+ternary+neural+networks+on+FPGA.+In+Proceedings+of+the+International+Conference+on+Field-programmable+Logic+and+Applications.
http://scholar.google.com/scholar?hl=en&q=Jiantao+Qiu%2C+Jie+Wang%2C+Song+Yao%2C+Kaiyuan+Guo%2C+Boxun+Li%2C+Erjin+Zhou%2C+Jincheng+Yu%2C+Tianqi+Tang%2C+Ningyi+Xu%2C+and+Sen+Song.+2016.+Going+deeper+with+embedded+FPGA+platform+for+convolutional+neural+network.+In+Proceedings+of+the+ACM%2FSIGDA+International+Symposium+on+Field-programmable+Gate+Arrays.+10.1145%2F2847263.2847265+
http://scholar.google.com/scholar?hl=en&q=Mohammad+Rastegari%2C+Vicente+Ordonez%2C+Joseph+Redmon%2C+and+Ali+Farhadi.+2016.+XNOR-Net%3A+ImageNet+classification+using+binary+convolutional+neural+networks.+In+Proceedings+of+the+European+Conference+on+Computer+Vision.
http://scholar.google.com/scholar?hl=en&q=Mohammad+S.+Razlighi%2C+Mohsen+Imani%2C+Farinaz+Koushanfar%2C+and+Tajana+Rosing.+2017.+LookNN%3A+Neural+network+with+no+multiplication.+In+Proceedings+of+the+Design%2C+Automation+and+Test+Conference+in+Europe.+
http://scholar.google.com/scholar?hl=en&q=Brandon+Reagen%2C+Paul+Whatmough%2C+Robert+Adolf%2C+Saketh+Rama%2C+Hyunkwang+Lee%2C+Sae-Kyu+Lee%2C+Jos%C3%A9+M.+Hern%C3%A1ndez-Lobato%2C+Gu-Yeon+Wei%2C+and+David+Brooks.+2016.+Minerva%3A+Enabling+low-power%2C+highly-accurate+deep+neural+network+accelerators.+In+ACM+SIGARCH+Computer+Architecture+News.+10.1109%2FISCA.2016.32+
http://scholar.google.com/scholar?hl=en&q=Michalis+Rizakis%2C+Stylianos+I.+Venieris%2C+Alexandros+Kouris%2C+and+Christos-Savvas+Bouganis.+2018.+Approximate+FPGA-based+LSTMs+under+computation+time+constraints.+In+Proceedings+of+the+International+Symposium+on+Applied+Reconfigurable+Computing.
http://scholar.google.com/scholar?hl=en&q=Adriana+Romero%2C+Nicolas+Ballas%2C+Samira+E.+Kahou%2C+Antoine+Chassang%2C+Carlo+Gatta%2C+and+Yoshua+Bengio.+2015.+FITNets%3A+Hints+for+thin+deep+nets.+In+Proceedings+of+the+International+Conference+on+Learning+Representations.
http://scholar.google.com/scholar?hl=en&q=Bita+D.+Rouhani%2C+Azalia+Mirhoseini%2C+and+Farinaz+Koushanfar.+2016.+Delight%3A+Adding+energy+dimension+to+deep+neural+networks.+In+Proceedings+of+the+International+Symposium+on+Low+Power+Electronics+and+Design.+10.1145%2F2934583.2934599+
http://scholar.google.com/scholar?hl=en&q=Bita+D.+Rouhani%2C+Azalia+Mirhoseini%2C+and+Farinaz+Koushanfar.+2017.+Deep3%3A+Leveraging+three+levels+of+parallelism+for+efficient+deep+learning.+In+Proceedings+of+the+Design+Automation+Conference.+10.1145%2F3061639.3062225+
http://scholar.google.com/scholar?hl=en&q=Charbel+Sakr%2C+Yongjune+Kim%2C+and+Naresh+Shanbhag.+2017.+Analytical+guarantees+on+numerical+precision+of+deep+neural+networks.+In+Proceedings+of+the+International+Conference+on+Machine+Learning.+
http://scholar.google.com/scholar?hl=en&q=Mohammad+Samragh%2C+Mohammad+Ghasemzadeh%2C+and+Farinaz+Koushanfar.+2017.+Customizing+neural+networks+for+efficient+FPGA+implementation.+In+Proceedings+of+the+IEEE+International+Symposium+on+Field-programmable+Custom+Computing+Machines.
http://scholar.google.com/scholar?hl=en&q=Eric+Schurman+and+Jake+Brutlag.+2009.+The+user+and+business+impact+of+server+delays%2C+additional+bytes%2C+and+HTTP+chunking+in+Web+search.+In+Proceedings+of+the+Velocity+Conference.
http://scholar.google.com/scholar?hl=en&q=Abigail+See%2C+Minh-Thang+Luong%2C+and+Christopher+D.+Manning.+2016.+Compression+of+neural+machine+translation+models+via+pruning.+In+Proceedings+of+the+SIGNLL+Conference+on+Computational+Natural+Language+Learning.
http://scholar.google.com/scholar?hl=en&q=Sayeh+Sharify%2C+Alberto+Delm%C3%A1s%2C+Kevin+Siu%2C+Patrick+Judd%2C+and+Andreas+Moshovos.+2018.+Loom%3A+Exploiting+weight+and+activation+precisions+to+accelerate+convolutional+neural+networks.+In+Proceedings+of+the+Design+Automation+Conference.+10.1145%2F3195970.3196072+
http://scholar.google.com/scholar?hl=en&q=Sayeh+Sharify%2C+Mostafa+Mahmoud%2C+Alberto+Delm%C3%A1s%2C+Milos+Nikolic%2C+and+Andreas+Moshovos.+2018.+Laconic+deep+learning+computing.+arXiv+preprint+arXiv%3A1805.04513+%282018%29.
http://scholar.google.com/scholar?hl=en&q=Hardik+Sharma%2C+Jongse+Park%2C+Divya+Mahajan%2C+Emmanuel+Amaro%2C+Joon+K.+Kim%2C+Chenkai+Shao%2C+Asit+Mishra%2C+and+Hadi+Esmaeilzadeh.+2016.+From+high-level+deep+neural+models+to+FPGAs.+In+Proceedings+of+the+IEEE%2FACM+International+Symposium+on+Microarchitecture.+
http://scholar.google.com/scholar?hl=en&q=Hardik+Sharma%2C+Jongse+Park%2C+Naveen+Suda%2C+Liangzhen+Lai%2C+Benson+Chau%2C+Vikas+Chandra%2C+and+Hadi+Esmaeilzadeh.+2018.+Bit+fusion%3A+Bit-level+dynamically+composable+architecture+for+accelerating+deep+neural+network.+In+Proceedings+of+the+International+Symposium+on+Computer+Architecture.+10.1109%2FISCA.2018.00069+
http://scholar.google.com/scholar?hl=en&q=Junzhong+Shen%2C+You+Huang%2C+Zelong+Wang%2C+Yuran+Qiao%2C+Mei+Wen%2C+and+Chunyuan+Zhang.+2018.+Towards+a+uniform+template-based+architecture+for+accelerating+2D+and+3D+CNNs+on+FPGA.+In+Proceedings+of+the+ACM%2FSIGDA+International+Symposium+on+Field-programmable+Gate+Arrays.+10.1145%2F3174243.3174257+
http://scholar.google.com/scholar?hl=en&q=Sungho+Shin%2C+Yoonho+Boo%2C+and+Wonyong+Sung.+2017.+Fixed-point+optimization+of+deep+neural+networks+with+adaptive+step+size+retraining.+In+Proceedings+of+the+IEEE+International+Conference+on+Acoustics%2C+Speech+and+Signal+Processing.
http://scholar.google.com/scholar?hl=en&q=Sungho+Shin%2C+Kyuyeon+Hwang%2C+and+Wonyong+Sung.+2016.+Fixed-point+performance+analysis+of+recurrent+neural+networks.+In+Proceedings+of+the+IEEE+International+Conference+on+Acoustics%2C+Speech+and+Signal+Processing.
http://scholar.google.com/scholar?hl=en&q=Nathan+Silberman+and+Sergio+Guadarrama.+2016.+TensorFlow-Slim+Image+Classification+Model+Library.+Retrieved+from+https%3A%2F%2Fgithub.com%2Ftensorflow%2Fmodels%2Ftree%2Fmaster%2Fresearch%2Fslim.
http://scholar.google.com/scholar?hl=en&q=Vikas+Sindhwani%2C+Tara+N.+Sainath%2C+and+Sanjiv+Kumar.+2015.+Structured+transforms+for+small-footprint+deep+learning.+In+Proceedings+of+the+Conference+on+Neural+Information+Processing+Systems.+
http://scholar.google.com/scholar?hl=en&q=Suraj+Srinivas+and+R.+Venkatesh+Babu.+2015.+Data-free+parameter+pruning+for+deep+neural+networks.+arXiv+preprint+arXiv%3A1507.06149+%282015%29.
http://scholar.google.com/scholar?hl=en&q=Nitish+Srivastava%2C+Geoffrey+Hinton%2C+Alex+Krizhevsky%2C+Ilya+Sutskever%2C+and+Ruslan+Salakhutdinov.+2014.+Dropout%3A+A+simple+way+to+prevent+neural+networks+from+overfitting.+J.+Mach.+Learn.+Res.+15%2C+1+%282014%29.+
http://scholar.google.com/scholar?hl=en&q=Jiang+Su%2C+Julian+Faraone%2C+Junyi+Liu%2C+Yiren+Zhao%2C+David+B.+Thomas%2C+Philip+H.+W.+Leong%2C+and+Peter+Y.+K.+Cheung.+2018.+Redundancy-reduced+MobileNet+acceleration+on+reconfigurable+logic+for+ImageNet+classification.+In+Proceedings+of+the+International+Symposium+on+Applied+Reconfigurable+Computing.
http://scholar.google.com/scholar?hl=en&q=Wonyong+Sung+and+Ki-Il+Kum.+1995.+Simulation-based+word-length+optimization+method+for+fixed-point+digital+signal+processing+systems.+IEEE+Trans.+Signal+Process.+43%2C+12+%281995%29.+10.1109%2F78.476465+
http://scholar.google.com/scholar?hl=en&q=Vivienne+Sze%2C+Yu-Hsin+Chen%2C+Tien-Ju+Yang%2C+and+Joel+S.+Emer.+2017.+Efficient+processing+of+deep+neural+networks%3A+A+tutorial+and+survey.+Proc.+IEEE+105%2C+12+%282017%29.
http://scholar.google.com/scholar?hl=en&q=Christian+Szegedy%2C+Sergey+Ioffe%2C+Vincent+Vanhoucke%2C+and+Alexander+A.+Alemi.+2017.+Inception-v4%2C+Inception-ResNet+and+the+impact+of+residual+connections+on+learning.+In+Proceedings+of+the+Association+for+the+Advancement+of+Artificial+Intelligence.+
http://scholar.google.com/scholar?hl=en&q=Cheng+Tai%2C+Tong+Xiao%2C+Yi+Zhang%2C+and+Xiaogang+Wang.+2016.+Convolutional+neural+networks+with+low-rank+regularization.+In+Proceedings+of+the+International+Conference+on+Learning+Representations.
http://scholar.google.com/scholar?hl=en&q=Wei+Tang%2C+Gang+Hua%2C+and+Liang+Wang.+2017.+How+to+train+a+compact+binary+neural+network+with+high+accuracy%3F+In+Proceedings+of+the+Association+for+the+Advancement+of+Artificial+Intelligence.+
http://scholar.google.com/scholar?hl=en&q=Karen+Ullrich%2C+Edward+Meeds%2C+and+Max+Welling.+2017.+Soft+weight-sharing+for+neural+network+compression.+In+Proceedings+of+the+International+Conference+on+Learning+Representations.
http://scholar.google.com/scholar?hl=en&q=Yaman+Umuroglu%2C+Nicholas+J.+Fraser%2C+Giulio+Gambardella%2C+Michaela+Blott%2C+Philip+H.+W.+Leong%2C+Magnus+Jahre%2C+and+Kees+Vissers.+2017.+FINN%3A+A+framework+for+fast%2C+scalable+binarized+neural+network+inference.+In+Proceedings+of+the+ACM%2FSIGDA+International+Symposium+on+Field-programmable+Gate+Arrays.+10.1145%2F3020078.3021744+
http://scholar.google.com/scholar?hl=en&q=Stylianos+I.+Venieris+and+Christos-Savvas+Bouganis.+2016.+fpgaConvNet%3A+A+framework+for+mapping+convolutional+neural+networks+on+FPGAs.+In+Proceedings+of+the+IEEE+International+Symposium+on+Field-programmable+Custom+Computing+Machines.
http://scholar.google.com/scholar?hl=en&q=Stylianos+I.+Venieris+and+Christos-Savvas+Bouganis.+2017.+Latency-driven+design+for+FPGA-based+convolutional+neural+networks.+In+Proceedings+of+the+International+Conference+on+Field-programmable+Logic+and+Applications.
http://scholar.google.com/scholar?hl=en&q=Erwei+Wang%2C+James+J.+Davis%2C+and+Peter+Y.+K.+Cheung.+2018.+A+PYNQ-based+framework+for+rapid+CNN+prototyping.+In+Proceedings+of+the+IEEE+International+Symposium+on+Field-programmable+Custom+Computing+Machines.
http://scholar.google.com/scholar?hl=en&q=Shuo+Wang%2C+Zhe+Li%2C+Caiwen+Ding%2C+Bo+Yuan%2C+Qinru+Qiu%2C+Yanzhi+Wang%2C+and+Yun+Liang.+2018.+C-LSTM%3A+Enabling+efficient+LSTM+using+structured+compression+techniques+on+FPGAs.+In+Proceedings+of+the+ACM%2FSIGDA+International+Symposium+on+Field-programmable+Gate+Arrays.+10.1145%2F3174243.3174253+
http://scholar.google.com/scholar?hl=en&q=Zhisheng+Wang%2C+Jun+Lin%2C+and+Zhongfeng+Wang.+2017.+Accelerating+recurrent+neural+networks%3A+A+memory-efficient+approach.+IEEE+Trans.+VLSI+Syst.+25%2C+10+%282017%29.
http://scholar.google.com/scholar?hl=en&q=Wei+Wen%2C+Chunpeng+Wu%2C+Yandan+Wang%2C+Yiran+Chen%2C+and+Hai+Li.+2016.+Learning+structured+sparsity+in+deep+neural+networks.+In+Proceedings+of+the+Conference+on+Neural+Information+Processing+Systems.+
http://scholar.google.com/scholar?hl=en&q=Darrell+Williamson.+1991.+Dynamically+scaled+fixed+point+arithmetic.+In+Proceedings+of+the+IEEE+Pacific+Rim+Conference+on+Communications%2C+Computers+and+Signal+Processing+Conference.
http://scholar.google.com/scholar?hl=en&q=Jiaxiang+Wu%2C+Cong+Leng%2C+Yuhang+Wang%2C+Qinghao+Hu%2C+and+Jian+Cheng.+2016.+Quantized+convolutional+neural+networks+for+mobile+devices.+In+Proceedings+of+the+IEEE+Conference+on+Computer+Vision+and+Pattern+Recognition.
http://scholar.google.com/scholar?hl=en&q=Shuang+Wu%2C+Guoqi+Li%2C+Feng+Chen%2C+and+Luping+Shi.+2018.+Training+and+inference+with+integers+in+deep+neural+networks.+In+Proceedings+of+the+International+Conference+on+Learning+Representations.
http://scholar.google.com/scholar?hl=en&q=Xilinx.+2018.+Versal%2C+the+First+Adaptive+Compute+Acceleration+Platform.+Retrieved+from+https%3A%2F%2Fwww.xilinx.com%2Fsupport%2Fdocumentation%2Fwhite_papers%2Fwp505-versal-acap.pdf.
http://scholar.google.com/scholar?hl=en&q=Tien-Ju+Yang%2C+Yu-Hsin+Chen%2C+and+Vivienne+Sze.+2017.+Designing+energy-efficient+convolutional+neural+networks+using+energy-aware+pruning.+In+Proceedings+of+the+IEEE+Conference+on+Computer+Vision+and+Pattern+Recognition.
http://scholar.google.com/scholar?hl=en&q=Tien-Ju+Yang%2C+Andrew+Howard%2C+Bo+Chen%2C+Xiao+Zhang%2C+Alec+Go%2C+Mark+Sandler%2C+Vivienne+Sze%2C+and+Hartwig+Adam.+2018.+NetAdapt%3A+Platform-aware+neural+network+adaptation+for+mobile+applications.+In+Proceedings+of+the+European+Conference+on+Computer+Vision.
http://scholar.google.com/scholar?hl=en&q=Zichao+Yang%2C+Marcin+Moczulski%2C+Misha+Denil%2C+Nando+de+Freitas%2C+Alex+Smola%2C+Le+Song%2C+and+Ziyu+Wang.+2015.+Deep+fried+convnets.+In+Proceedings+of+the+International+Conference+on+Computer+Vision.+10.1109%2FICCV.2015.173+
http://scholar.google.com/scholar?hl=en&q=Chen+Zhang%2C+Zhenman+Fang%2C+Peipei+Zhou%2C+Peichen+Pan%2C+and+Jason+Cong.+2016.+Caffeine%3A+Towards+uniformed+representation+and+acceleration+for+deep+convolutional+neural+networks.+In+Proceedings+of+the+International+Conference+On+Computer+Aided+Design.+10.1145%2F2966986.2967011+
http://scholar.google.com/scholar?hl=en&q=Jialiang+Zhang+and+Jing+Li.+2018.+PQ-CNN%3A+Accelerating+product+quantized+convolutional+neural+network+on+FPGA.+In+Proceedings+of+the+International+Symposium+on+Field-programmable+Custom+Computing+Machines.
http://scholar.google.com/scholar?hl=en&q=Xiaofan+Zhang%2C+Xinheng+Liu%2C+Anand+Ramachandran%2C+Chuanhao+Zhuge%2C+Shibin+Tang%2C+Peng+Ouyang%2C+Zuofu+Cheng%2C+Kyle+Rupnow%2C+and+Deming+Chen.+2017.+High-performance+video+content+recognition+with+long-term+recurrent+convolutional+network+for+FPGA.+In+Proceedings+of+the+International+Conference+on+Field-programmable+Logic+and+Applications.
http://scholar.google.com/scholar?hl=en&q=Ritchie+Zhao%2C+Weinan+Song%2C+Wentao+Zhang%2C+Tianwei+Xing%2C+Jeng-Hau+Lin%2C+Mani+Srivastava%2C+Rajesh+Gupta%2C+and+Zhiru+Zhang.+2017.+Accelerating+binarized+convolutional+neural+networks+with+software-programmable+FPGAs.+In+Proceedings+of+the+ACM%2FSIGDA+International+Symposium+on+Field-programmable+Gate+Arrays.+10.1145%2F3020078.3021741+
http://scholar.google.com/scholar?hl=en&q=Aojun+Zhou%2C+Anbang+Yao%2C+Yiwen+Guo%2C+Lin+Xu%2C+and+Yurong+Chen.+2016.+Incremental+network+quantization%3A+Towards+lossless+CNNs+with+low-precision+weights.+In+Proceedings+of+the+International+Conference+on+Learning+Representations.
http://scholar.google.com/scholar?hl=en&q=Hao+Zhou%2C+Jose+M.+Alvarez%2C+and+Fatih+Porikli.+2016.+Less+is+more%3A+Towards+compact+CNNs.+In+Proceedings+of+the+European+Conference+on+Computer+Vision.
http://scholar.google.com/scholar?hl=en&q=Shuchang+Zhou%2C+Zekun+Ni%2C+Xinyu+Zhou%2C+He+Wen%2C+Yuxin+Wu%2C+and+Yuheng+Zou.+2016.+DoReFa-Net%3A+Training+low+bitwidth+convolutional+neural+networks+with+low+bitwidth+gradients.+arXiv+preprint+arXiv%3A1606.06160+%282016%29.
http://scholar.google.com/scholar?hl=en&q=Chenzhuo+Zhu%2C+Song+Han%2C+Huizi+Mao%2C+and+William+J.+Dally.+2017.+Trained+ternary+quantization.+In+Proceedings+of+the+International+Conference+on+Learning+Representations.
http://scholar.google.com/scholar?hl=en&q=Shilin+Zhu%2C+Xin+Dong%2C+and+Hao+Su.+2018.+Binary+ensemble+neural+network%3A+More+bits+per+network+or+more+networks+per+bit%3F+arXiv+preprint+arXiv%3A1806.07550+%282018%29.
